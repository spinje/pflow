---
title: "LLM"
description: "Call AI models with prompts and images"
icon: "sparkles"
---

<Note>
  **Agent commands.** Your AI agent uses this node in workflows. You don't configure it directly.
</Note>

The LLM node calls AI models using [Simon Willison's llm library](https://llm.datasette.io/). It supports multiple providers (OpenAI, Anthropic, Google, local models) through a unified interface.

## Parameters

| Parameter | Type | Required | Default | Description |
|-----------|------|----------|---------|-------------|
| `prompt` | str | Yes | - | Text prompt to send to the model |
| `model` | str | No | `gpt-4o-mini` | Model identifier |
| `system` | str | No | - | System prompt for behavior guidance |
| `temperature` | float | No | `1.0` | Sampling temperature (0.0-2.0) |
| `max_tokens` | int | No | - | Maximum response tokens |
| `images` | list | No | `[]` | Image URLs or file paths for vision models |

## Output

| Key | Type | Description |
|-----|------|-------------|
| `response` | any | Model's response (auto-parsed JSON or string) |
| `llm_usage` | dict | Token usage metrics |
| `error` | str | Error message (only present on failure) |

### Token usage structure

```json
{
  "model": "gpt-4o-mini",
  "input_tokens": 150,
  "output_tokens": 89,
  "total_tokens": 239,
  "cache_creation_input_tokens": 0,
  "cache_read_input_tokens": 0
}
```

## Model support

The LLM node supports any model available through the `llm` library:

| Provider | Example models | Setup |
|----------|---------------|-------|
| OpenAI | `gpt-4o`, `gpt-4o-mini`, `gpt-4` | `OPENAI_API_KEY` env var |
| Anthropic | `claude-sonnet-4-20250514`, `claude-opus-4-0` | `ANTHROPIC_API_KEY` + `llm-anthropic` plugin |
| Google | `gemini-2.0-flash`, `gemini-pro` | Provider-specific setup |
| Local | Depends on plugin | `llm-ollama`, `llm-gpt4all` |

<Tip>
  Run `llm models` to see all available models on your system.
</Tip>

## Automatic JSON parsing

The node automatically detects and parses JSON responses:

```json
{
  "id": "analyze",
  "type": "llm",
  "params": {
    "prompt": "List 3 colors as JSON array",
    "model": "gpt-4o-mini"
  }
}
```

If the response is valid JSON (including markdown-wrapped JSON), `response` will be the parsed object/array. Otherwise, it's the raw string.

## Image support

For vision-capable models, pass image URLs or local file paths:

```json
{
  "id": "describe",
  "type": "llm",
  "params": {
    "prompt": "What's in this image?",
    "model": "gpt-4o",
    "images": ["photo.jpg"]
  }
}
```

Supported formats: JPEG, PNG, GIF, WebP, PDF

Images can be:
- Local file paths: `photo.jpg`, `/path/to/image.png`
- URLs: `https://example.com/image.jpg`

## Examples

### Basic prompt

```json
{
  "nodes": [
    {
      "id": "summarize",
      "type": "llm",
      "params": {
        "prompt": "Summarize: ${read.content}",
        "model": "gpt-4o-mini"
      }
    }
  ]
}
```

### With system prompt

```json
{
  "nodes": [
    {
      "id": "translate",
      "type": "llm",
      "params": {
        "system": "You are a translator. Respond only with the translation.",
        "prompt": "Translate to Spanish: ${input.text}",
        "temperature": 0.3
      }
    }
  ]
}
```

### Structured output

```json
{
  "nodes": [
    {
      "id": "extract",
      "type": "llm",
      "params": {
        "system": "Extract entities as JSON with keys: people, places, organizations",
        "prompt": "${document.content}"
      }
    }
  ]
}
```

The response will be automatically parsed if it's valid JSON.

### Image analysis

```json
{
  "nodes": [
    {
      "id": "analyze",
      "type": "llm",
      "params": {
        "prompt": "Describe the main elements in this image",
        "model": "gpt-4o",
        "images": ["${file_path}"]
      }
    }
  ]
}
```

## Error handling

| Error | Cause | Solution |
|-------|-------|----------|
| Unknown model | Model ID not recognized | Run `llm models` to see available models |
| API key required | Missing credentials | Set up with `llm keys set <provider>` or env var |
| Rate limit | Too many requests | Wait and retry automatically (built-in retry) |

The node retries transient failures automatically (3 attempts, 1 second wait).

## Temperature guide

| Value | Use case |
|-------|----------|
| 0.0-0.3 | Factual tasks, code generation, structured output |
| 0.5-0.7 | Balanced creativity and consistency |
| 0.8-1.2 | Creative writing, brainstorming |
| 1.5-2.0 | Maximum randomness (use sparingly) |

Values outside 0.0-2.0 are clamped automatically.
