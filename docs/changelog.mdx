---
title: "Changelog"
description: "Product updates and announcements"
icon: "clock"
rss: true
---

<Update label="JANUARY 2026" description="v0.5.0" tags={["New releases", "Bug fixes"]}>
  ## Batch Processing

  Workflows now support processing arrays of data through a single node using isolated execution contexts. This enables powerful fan-out patterns for mass data transformation and analysis.

  **Highlights**
  - Added sequential and parallel batch execution modes with configurable concurrency limits.
  - Added real-time progress indicators in the CLI showing item completion status.
  - Added automatic LLM usage and cost tracking for all sub-executions within a batch.
  - Added self-contained batch results by including the original input item in the output schema.
  - Improved batch validation to support dotted references and nested structures.

  ## Intelligent Data Flow

  Significant improvements to the template engine make it easier to pipe data between different tools without manual parsing or string manipulation.

  **Highlights**
  - Added automatic JSON parsing during nested template access, allowing variables like `${node.stdout.field}` to work even when the source is a JSON string.
  - Added type preservation for simple templates in inline objects to prevent double-serialization bugs.
  - Added automatic coercion of complex types (dicts/lists) to JSON strings when mapped to string-only parameters.
  - Added normalized type string validation across the registry and workflow nodes to prevent matching failures.
  - Improved workflow input resolution to handle optional variables without default values.

  ## Shell & Node Reliability

  Enhancements to the shell execution environment and core node integrations provide better visibility into failures and more predictable behavior.

  **Highlights**
  - Migrated the Claude Code node to the Claude Agent SDK with new sandbox configuration support.
  - Added visibility for shell `stderr` output when exit codes are successful to help debug silent pipeline failures.
  - Added automatic stripping of trailing newlines from shell `stdout` by default.
  - Added a "smart handling" check for shell pipelines to correctly catch errors in commands like `grep` or `sed`.
  - Added support for branch and tag references in the Git Log node.
  - Fixed a critical bug where `SIGPIPE` signals could prematurely terminate workflows when subprocesses ignored input.

  <Accordion title="Breaking changes">
    ### Parameter-Only Pattern
    The "shared store fallback" pattern has been removed from all nodes. Nodes now read exclusively from `self.params`. All data wiring must be done explicitly using `${variable}` templates in the workflow configuration. This prevents naming collisions between node IDs and parameter names.

    ### Claude Code Node
    - Parameter `task` renamed to `prompt`
    - Parameter `working_directory` renamed to `cwd`
    - Parameter `context` removed (include context directly in the prompt)

    ### Workflow Metadata
    - The `name` field is no longer stored inside workflow JSON files. Names are now derived directly from the filename to ensure the filesystem remains the single source of truth.
  </Accordion>
</Update>

<Update label="December 2024" description="v0.7.0" tags={["New releases", "Improvements"]}>
  ## Batch processing

  Process arrays of items through a single node with built-in error handling and optional parallel execution.

  **Features**
  - Sequential or parallel execution modes
  - Configurable concurrency limits (`max_concurrent`)
  - Per-item retry with configurable wait time
  - Error handling: fail-fast (stop on first error) or continue (process all items)
  - Results preserve input order even in parallel mode

  <Accordion title="Example">
    ```json
    {
      "id": "summarize_files",
      "type": "llm",
      "batch": {
        "items": "${list_files.files}",
        "as": "file",
        "parallel": true,
        "max_concurrent": 5
      },
      "params": {
        "prompt": "Summarize: ${file.content}"
      }
    }
    ```
  </Accordion>

  ## Unified LLM model support

  Configure which models pflow uses for discovery, filtering, and workflow execution.

  **Model configuration**
  - New `pflow settings llm` commands for model management
  - Single `default_model` setting applies to all pflow features
  - Feature-specific overrides for discovery and filtering
  - Works with any llm-supported provider (OpenAI, Anthropic, Google, local models)

  **Bug fixes**
  - User model choice now respected in workflows (was silently overridden)
  - Invalid model names properly error instead of silent failures
  - Consistent behavior between `registry run` and workflow execution

  <Accordion title="Quick setup">
    ```bash
    # Set an API key (pflow auto-detects the model)
    pflow settings set-env OPENAI_API_KEY "sk-..."

    # Or override the auto-detected model
    pflow settings llm set-default gpt-5.2
    ```
  </Accordion>

  <Accordion title="Breaking changes">
    Discovery and filtering commands no longer require an Anthropic API key - any llm-supported provider works.

    LLM nodes in workflows now use the same resolution as discovery:
    1. Workflow params (`"model": "gpt-5.2"`)
    2. `pflow settings llm set-default`
    3. `llm models default` (llm CLI)
    4. Auto-detect from API keys
    5. Error with setup instructions
  </Accordion>
</Update>

<Update label="December 2024" description="v0.6.0" tags={["New releases"]}>
  ## Initial release

  pflow v0.6.0 — compile agent reasoning into reusable workflows.

  **Workflow engine**
  - Natural language → compiled workflows
  - Save workflows for instant reuse
  - Type-aware templates with auto-parsing and nested access
  - Stdin/stdout pipe integration
  - Validation with suggestions and actionable error messages
  - Execution traces for debugging

  **Built-in nodes**
  - File operations (read, write, copy, move, delete)
  - LLM calls (any model via `llm` library)
  - HTTP requests (all methods, auth, binary support)
  - Shell commands (with dangerous pattern blocking)
  - Claude Code for agentic tasks
  - MCP bridge — connect any MCP server (stdio and HTTP transports)

  **Agent integration**
  - MCP server with 11 tools for workflow building
  - Intelligent discovery of nodes and workflows
  - Run individual nodes without workflows (`registry run`)
  - Structure-only mode — AI sees schema types, not data
  - Instructions system for agent guidance
  - Works with all MCP-compatible and local agents

  <Accordion title="Quick start">
    ```bash
    uv tool install git+https://github.com/spinje/pflow.git
    pflow settings set-env OPENAI_API_KEY "sk-..."
    ```
    See [Quickstart](/quickstart) for full setup.
  </Accordion>

  <Accordion title="Limitations">
    - Currently supports macOS only
    - Shell commands run with user privileges (not sandboxed)
    - No conditional branching yet
  </Accordion>

  <Accordion title="What's next">
    See the [Roadmap](/roadmap) — conditional branching, task parallelism, and benchmarking coming soon.
  </Accordion>
</Update>
