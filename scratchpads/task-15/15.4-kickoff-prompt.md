# Task 15.4 Kickoff Prompt: Integration Testing and Documentation

## ğŸ¯ Your Mission

You are implementing **subtask 15.4** of Task 15: "Integration and Comprehensive Testing". Your job is to create comprehensive testing and documentation for the two-phase context builder system that was implemented in the previous subtasks.

**IMPORTANT**: The functionality is already complete and working. You are NOT implementing new features - you are adding tests and documentation for existing functionality.

### 2. Understand What Currently Exists
- **33 tests** in `tests/test_planning/test_context_builder_phases.py` (unit tests)
- **12 tests** in `tests/test_planning/test_workflow_loading.py` (workflow loading)
- **Zero integration tests** - this is what you need to add
- **No documentation** of the enhanced docstring format - this is what you need to create

### 3. Your Deliverables

#### A. Document Enhanced Docstring Format (2 hours)
Create `docs/reference/enhanced-interface-format.md` with:
- How to write structured docstrings for pflow nodes
- Examples of the `Interface:` section format
- How to document nested structures (dict, list)
- Parser limitations and gotchas
- Working examples from existing nodes

#### B. Add Integration Tests (3-4 hours)
Create `tests/test_integration/test_context_builder_integration.py` with:
- Tests for discovery â†’ planning workflow
- Tests with structured nodes (`test_node_structured`)
- Error recovery flow tests
- Workflow integration tests
- Real-world scenario tests

#### C. Add Edge Case Tests (2 hours)
Add tests for:
- Performance with large registries (1000+ nodes)
- Unicode characters in descriptions
- Concurrent workflow loading
- Malformed data handling

#### D. Verify Coverage (1 hour)
- Run coverage analysis
- Ensure >90% coverage for context builder module
- Add tests for any missing coverage
- Verify all tests pass

## ğŸš€ Quick Start Guide

### Step 1: Verify Current State
```bash
# Run existing tests to ensure everything works
make test
make check

# Check current test coverage
uv run pytest tests/test_planning/ --cov=src/pflow/planning/context_builder --cov-report=term-missing
```

### Step 2: Start with Documentation
Create the enhanced docstring format documentation first. Use these existing examples:
- `src/pflow/nodes/test_node_structured.py` - Has complex structures
- `src/pflow/nodes/file/read_file.py` - Simple example
- `src/pflow/registry/metadata_extractor.py` lines 543-612 - The parser

### Step 3: Add Integration Tests
Start with this basic test structure:

```python
# tests/test_integration/test_context_builder_integration.py
def test_discovery_to_planning_flow():
    """Test the complete workflow users will experience."""
    from pflow.registry import Registry
    from pflow.planning.context_builder import build_discovery_context, build_planning_context

    # 1. Load real registry
    registry = Registry()
    metadata = registry.load()

    # 2. Discovery phase (what user sees first)
    discovery = build_discovery_context(registry_metadata=metadata)
    assert "## Available Nodes" in discovery
    assert "read-file" in discovery  # Should include file nodes

    # 3. Planning phase (after user selects components)
    planning = build_planning_context(["read-file", "write-file"], [], metadata)
    assert "## Selected Components" in planning
    assert "**Inputs**:" in planning
    assert "**Outputs**:" in planning
```

### Step 4: Test the Key Value Proposition
The most important test is one that shows the complete user journey:
1. User discovers available components (discovery context)
2. User selects relevant components
3. User gets detailed information (planning context)
4. User can generate a working workflow

## ğŸ¯ Success Criteria

You're done when:
- [ ] Enhanced docstring format is fully documented with examples
- [ ] Integration tests cover discovery â†’ planning workflow
- [ ] Edge cases are tested (performance, Unicode, concurrency)
- [ ] Test coverage >90% for context builder module
- [ ] All tests pass (`make test` succeeds)
- [ ] Code quality passes (`make check` succeeds)
- [ ] A developer can read your docs and write properly formatted nodes

## âš ï¸ Critical Warnings

1. **Don't modify the structure parser** (lines 543-612 in metadata_extractor.py) - it's fragile but working
2. **Use `test_node_structured` for structure testing** - file nodes don't have structures
3. **Don't test deprecated functions** - they've been removed
4. **Focus on integration, not units** - unit tests already exist

## ğŸ”§ Key Functions to Test

The main functions you need to test are:
- `build_discovery_context()` - Lightweight component browsing
- `build_planning_context()` - Detailed interface information
- `_format_structure_combined()` - The enhanced structure display format

## ğŸ“ Key Files to Know

- `/src/pflow/planning/context_builder.py` - Main implementation
- `/tests/test_planning/test_context_builder_phases.py` - Existing unit tests
- `/src/pflow/nodes/test_node_structured.py` - Node with complex structures
- `.taskmaster/tasks/task_15/task-15-context-builder-ambiguities.md` - Decision 9 explains the format

## ğŸš€ Ready to Begin?

1. Read the handoff document thoroughly
2. Review the implementation plan
3. Understand the current test coverage
4. Start with documentation, then integration tests
5. Focus on the user journey: discovery â†’ selection â†’ planning â†’ workflow generation

Remember: You're documenting and testing something that already works. The implementation is complete, solid, and tested at the unit level. Your job is to add the missing integration tests and documentation that will help future developers understand and use this system effectively.

**When you're ready to start, confirm that you've read and understood this kickoff prompt and the handoff documents.**
