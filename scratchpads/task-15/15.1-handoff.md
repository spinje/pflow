# Subtask 15.1 Handoff: Workflow Loading Infrastructure

**IMPORTANT**: Do not begin implementing yet. Read this entire handoff first and confirm you're ready to begin.

## üéØ Critical Context You Need to Know

### The Chicken-and-Egg Problem
Task 15 needs to load workflows that don't exist yet because workflow saving is implemented in Task 17. Your solution: Create the loading infrastructure now that Task 17 will use for saving. This means you're creating:
- The directory structure (`~/.pflow/workflows/`)
- The loading function that expects a specific JSON schema
- Test workflows to validate your implementation

### Core Outcomes This Subtask Must Deliver
1. **`_load_saved_workflows()` function** in `src/pflow/planning/context_builder.py` that:
   - Creates `~/.pflow/workflows/` if missing (use `os.makedirs(Path.home() / '.pflow' / 'workflows', exist_ok=True)`)
   - Loads all `*.json` files from the directory
   - Validates ONLY essential fields: `name`, `description`, `inputs`, `outputs`, `ir`
   - Skips invalid files with warnings (DO NOT crash)
   - Returns list of workflow metadata dicts

2. **Test workflows** in the workflows directory:
   - 2-3 valid workflows using test nodes (`test_node`, `test_node_structured`)
   - 1-2 invalid workflows for error testing
   - DO NOT use file operation nodes (slow, create real files)

### üö® Critical Warnings from Task 14 Implementation

The metadata extractor has EXTREMELY FRAGILE regex patterns. While you won't modify the parser, you need to know:
- **Line 374**: Comma-aware splitting for shared keys
- **Line 416**: Exclusive params pattern (params in Reads are filtered out)
- **Lines 543-612**: Structure parser is FULLY IMPLEMENTED (not scaffolding!)
- One wrong regex change broke 20+ tests in Task 14

### Key Decisions Already Made

From `.taskmaster/tasks/task_15/task-15-context-builder-ambiguities.md`:

1. **Workflow Storage** (Decision 1):
   - Simple flat directory: `~/.pflow/workflows/`
   - Files named: `{workflow-name}.json`
   - Overwrite on name conflicts (last write wins)
   - No subdirectories in MVP

2. **Workflow Schema** (Decision 2):
   ```json
   {
     "name": "fix-github-issue",
     "description": "Analyzes issue and creates PR with fix",
     "inputs": ["issue_number"],
     "outputs": ["pr_number", "summary"],
     "created_at": "2024-01-15T10:30:00Z",  // Optional
     "updated_at": "2024-01-15T10:30:00Z",  // Optional
     "version": "1.0.0",                    // Optional
     "ir_version": "0.1.0",                 // Required
     "tags": ["github", "automation"],      // Optional
     "ir": { /* Full workflow IR */ }      // Required
   }
   ```
   - User chose Option B (full metadata) but you only validate essentials
   - Tags can default to empty array, version to "1.0.0"

3. **Error Handling** (Decision 7):
   - Skip invalid files with warning logs
   - Don't crash on malformed JSON
   - Log but continue on missing fields

### Test Node Usage Pattern

From Task 11's implementation, use test nodes like this:
```python
from pflow.nodes.test_node import TestNode
from pflow.nodes.test_node_structured import TestNodeStructured  # If it exists
```

These are pure in-memory operations - perfect for testing without side effects.

### Unexpected Discoveries That Changed Approach

1. **No backward compatibility needed** for `build_context()` - user clarified only tests use it
2. **Context size limit is 200KB**, not 50KB (from line 38 in context_builder.py)
3. **All 7 nodes already migrated** to enhanced format in Task 14
4. **Combined JSON + paths format is MANDATORY** - not optional

### Files You'll Need

- **Modify**: `/Users/andfal/projects/pflow/src/pflow/planning/context_builder.py`
- **Use**: `/Users/andfal/projects/pflow/src/pflow/nodes/test_node.py`
- **Check if exists**: `/Users/andfal/projects/pflow/src/pflow/nodes/test_node_structured.py`

### Essential Context Documents (READ THESE FIRST)

**‚ö†Ô∏è CRITICAL**: Read these Task 15 documents for full context, but remember you're ONLY implementing subtask 15.1:
- `.taskmaster/tasks/task_15/task-15-context-builder-ambiguities.md` - All design decisions including workflow schema
- `.taskmaster/tasks/task_15/task-15-technical-implementation-guide.md` - Line numbers and implementation details

These documents cover the ENTIRE Task 15, but you must ONLY implement:
- `_load_saved_workflows()` function
- Test workflow JSON files
- Directory creation logic

**DO NOT** implement:
- `build_discovery_context()` (that's subtask 15.2)
- `build_planning_context()` (that's subtask 15.2)
- Structure display enhancements (that's subtask 15.3)
- Any refactoring of `build_context()` (that's subtask 15.4)

Your ONLY job is to create the workflow loading infrastructure. Nothing more.

### Example Test Workflow Structure

```json
{
  "name": "test-data-pipeline",
  "description": "Processes user data through multiple transformations",
  "inputs": ["user_id"],
  "outputs": ["processed_data"],
  "ir_version": "0.1.0",
  "ir": {
    "nodes": [
      {
        "id": "fetch",
        "type": "test-node-structured",
        "params": {"user_id": "$user_id"}
      },
      {
        "id": "process",
        "type": "test-node",
        "params": {}
      }
    ],
    "edges": [
      {"from": "fetch", "to": "process", "condition": "default"}
    ]
  }
}
```

### Anti-Patterns to Avoid

1. **Don't over-validate** - Task 17 will handle comprehensive validation
2. **Don't implement saving** - That's Task 17's job
3. **Don't modify any parser regex** - They're fragile and working
4. **Don't use file operation nodes** in test workflows - too slow
5. **Don't enforce artificial size limits** - Modern LLMs have huge contexts

### What Would Make Me Furious If I Forgot to Mention

1. The `_load_saved_workflows()` function returns a **list of dicts**, not a dict
2. Use `Path.home()` for cross-platform home directory (not `~` expansion)
3. Workflow names in the list should match the `name` field, not the filename
4. Empty directory should return empty list, not error
5. Invalid JSON should log warning but not stop loading other files
6. The function should be "private" (underscore prefix) since it's internal

### Integration Points

Your `_load_saved_workflows()` will be called by:
- `build_discovery_context()` (subtask 15.2)
- `build_planning_context()` (subtask 15.2)

So the return format must be consistent and predictable.

### üß™ CRITICAL: Test-As-You-Go Strategy

**From CLAUDE.md and all completed tasks**: Tests are NOT a separate activity - they're part of implementation!

1. **Write tests FIRST or ALONGSIDE your code** (TDD encouraged):
   - Create `tests/test_planning/test_workflow_loading.py`
   - Test directory creation
   - Test loading valid workflows
   - Test handling invalid JSON
   - Test missing required fields
   - Test empty directory
   - Test file permissions issues

2. **Pattern from successful tasks**:
   ```python
   def test_load_workflows_creates_directory_if_missing(tmp_path):
       """Test that _load_saved_workflows creates the directory."""
       workflow_dir = tmp_path / ".pflow" / "workflows"
       assert not workflow_dir.exists()

       # Your implementation should create it
       workflows = _load_saved_workflows(workflow_dir)

       assert workflow_dir.exists()
       assert workflows == []
   ```

3. **Run tests continuously**:
   - After each small change: `pytest tests/test_planning/test_workflow_loading.py`
   - Before finalizing: `make test`
   - Check coverage: `make check`

4. **Test the real paths**:
   - Create actual JSON files in test directories
   - Test with `tmp_path` fixture for isolation
   - Clean up in test teardown

**Remember**: A task without tests is an INCOMPLETE task. Tests prove your implementation works and prevent regressions when other subtasks build on your work.

---

**Remember**: Read all of this first, understand the context, then confirm you're ready to begin implementation. The workflow loading infrastructure you create here is the foundation for workflow reuse - the core value proposition of pflow.
