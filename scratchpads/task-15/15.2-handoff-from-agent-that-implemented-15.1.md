# Subtask 15.2 Handoff: Two-Phase Context Functions

**IMPORTANT**: Do not begin implementing yet. Read this entire handoff first and confirm you're ready to begin.

## üéØ What You're Building On

I just implemented `_load_saved_workflows()` in `src/pflow/planning/context_builder.py` (lines 258-385). This function:
- Creates `~/.pflow/workflows/` if missing
- Loads all `*.json` files from that directory
- Returns a **list of dicts** (not a dict!) with workflow metadata
- Skips invalid files with warnings (doesn't crash)
- Already validates required fields: name, description, inputs, outputs, ir

## üîß Critical Functions You'll Reuse

### Already Exist and Work:
- **`_process_nodes()`** (lines 26-107): Extracts metadata from registry, filters test nodes
- **`_format_node_section()`** (lines 388-531): Formats full node details WITH exclusive params
- **`_group_nodes_by_category()`** (lines 231-255): Groups nodes (file ops, AI/LLM, etc.)
- **`_format_structure()`** (lines 199-228): Formats hierarchical structures BUT needs enhancement

### Exclusive Params Pattern (Line 416):
```python
# This is ALREADY IMPLEMENTED - just reuse it!
input_keys = set()
for inp in inputs:
    if isinstance(inp, dict):
        input_keys.add(inp["key"])
    else:
        input_keys.add(inp)
```
The params displayed are filtered to exclude any that appear in inputs. This is critical for the planner.

## ‚ö†Ô∏è Critical Warnings

### 1. Metadata Extractor is FRAGILE
- DO NOT modify any regex patterns in `metadata_extractor.py`
- One wrong change broke 20+ tests in Task 14
- The parser is fully functional but delicate

### 2. Missing Components Decision (Task 15 Ambiguities Doc, Decision 8)
When components are missing in `build_planning_context()`:
```python
# Return error dict, DON'T skip!
return {
    "error": error_msg,
    "missing_nodes": missing_nodes,
    "missing_workflows": missing_workflows
}
```
This enables the planner to retry discovery. Skipping would create broken workflows.

### 3. No Placeholders for Missing Descriptions
If a node/workflow has no description, omit the description line entirely. Don't add "No description" or similar.

## üìÅ Test Resources I Created

### Test Workflows in `/tests/test_planning/fixtures/workflows/`:
- `test-data-pipeline.json` - Multi-node workflow with edges
- `test-simple-workflow.json` - Single node workflow
- `test-retry-workflow.json` - Uses test-node-retry
- `invalid-missing-name.json` - For error testing
- `invalid-bad-json.json` - Malformed JSON

### Test Infrastructure:
- `tests/test_planning/test_workflow_loading.py` - Shows how to test with monkeypatch
- Uses `tmp_path` fixture for isolated testing
- Pattern: Mock `Path.home()` to avoid real home directory

## üèóÔ∏è Architecture Insights

### Current State:
- `build_context()` creates single-phase context (all nodes, full details)
- It's at line 110 and can be refactored freely (no backward compatibility needed)
- MAX_OUTPUT_SIZE = 200KB (line 17) - NOT 50KB as some docs say

### What You're Creating:
1. **Discovery Context**: Names + descriptions only, grouped by category
2. **Planning Context**: Full details for selected components only

### Reuse Pattern:
```python
# Discovery can reuse grouping:
categories = _group_nodes_by_category(processed_nodes)

# Planning can reuse formatting:
section = _format_node_section(node_type, node_data)
```

## üêõ Subtle Edge Cases

### 1. Test Nodes Already Filtered
`_process_nodes()` already skips test nodes (line 48). But `_load_saved_workflows()` doesn't filter test workflows - you might want to.

### 2. Dynamic Imports Cache
`_process_nodes()` caches imported modules (line 39). This speeds up repeated calls.

### 3. Structure Display TODO
The ambiguities doc (Decision 9) requires "Combined JSON + paths format" for structures. Current `_format_structure()` only does hierarchical format. You'll need to enhance it or create a new method.

## üìä Performance Characteristics

- `_process_nodes()` is the bottleneck (imports + metadata extraction)
- With 100 nodes, expect ~1-2 seconds
- Workflow loading is fast (<100ms for typical counts)
- No artificial size limits needed for MVP

## üîó Essential Reading

### Must Read First:
1. `.taskmaster/tasks/task_15/task-15-context-builder-ambiguities.md` - All design decisions
2. `.taskmaster/tasks/task_15/task-15-technical-implementation-guide.md` - Line numbers, patterns

### Key Sections:
- Ambiguities Doc, Decision 8: Missing components handling
- Ambiguities Doc, Decision 9: Structure display format
- Technical Guide, lines 233-260: Methods to reuse

## üí° Unexpected Discoveries

1. **All nodes already migrated** to enhanced format (Task 14.3)
2. **Structure parser is complete** - not scaffolding (lines 543-612 in metadata_extractor)
3. **build_context() has no dependencies** - can be completely rewritten
4. **Workflows have no category** - you'll need to decide how to group them

## üéÅ What Would Save You Time

1. Start by copying the structure of `build_context()` for both new functions
2. The error checking at the start of `build_context()` (lines 121-125) is good boilerplate
3. For testing missing components, create a registry dict manually - don't need real nodes
4. The logging pattern is consistent: debug for missing, warning for errors, info for summaries

## ü§î Open Questions You'll Face

1. Should workflows have their own category or mix with nodes?
2. How to handle workflow "types" for categorization?
3. Should test workflows be filtered in discovery?
4. What's the exact markdown format for workflow discovery?

## Final Note

The foundation is solid. You have working functions to load workflows, extract metadata, and format nodes. The main challenge is orchestrating these pieces into two clean phases while handling the missing components case elegantly.

Good luck! The code is well-structured for what you need to build.
