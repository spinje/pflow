# Subtask 14.1 Handoff: Critical Knowledge Transfer

**⚠️ IMPORTANT**: Do NOT begin implementing yet. Read this entire handoff and confirm you understand before starting.

## The Aha Moments You Need to Know

### 1. "Writes = Outputs" (This Took Me Time to Discover)
The Interface section uses `Writes:` to document what other systems call "outputs". There is NO separate `Outputs:` section anywhere. This is verified in the actual codebase. When you see "outputs" in metadata, it comes from parsing "Writes:".

### 2. The Parser Extension Point is `_extract_list_section()`
Don't create a new parser from scratch. The current system has a method called `_extract_list_section()` in `metadata_extractor.py` that extracts simple lists. This is your starting point. Study it carefully - it handles the regex matching and extraction patterns you'll need to extend.

### 3. The Current INTERFACE_PATTERN is Fragile Gold
```python
INTERFACE_PATTERN = re.compile(
    r"Interface:\s*\n((?:[-\s]*(?:Reads|Writes|Params|Actions):.*(?:\n|$))+)",
    re.MULTILINE
)
```
This pattern is carefully crafted. The optional newlines (`\n?`), the non-greedy matching - every character matters. When extending it, test extensively. Task 7's review warned about this.

## Critical Format Decisions Already Made

### Detection Logic: It's All About the Colon
```python
# Old format (no colon after key):
Writes: shared["content"], shared["error"]

# New format (colon after key indicates type):
Writes: shared["content"]: str, shared["error"]: str
```
Your parser detects format by looking for `:` after `shared["key"]` or after param names.

### Indentation-Based Parsing (NOT Regex Hell)
We chose indentation over complex regex for structures:
```python
Writes: shared["issue_data"]: dict
    - number: int  # Issue number
    - user: dict  # Author info
      - login: str  # GitHub username
```
Don't try to parse this with regex. Use indentation levels like YAML parsers do.

### Storage Format Change
Current format:
```python
{
    "outputs": ["content", "error"],  # Simple strings
    "inputs": ["file_path"],
    "params": ["encoding"]
}
```

Your new format:
```python
{
    "outputs": [
        {"key": "content", "type": "str", "description": "File contents"},
        {"key": "error", "type": "str", "description": "Error message"}
    ],
    "inputs": [
        {"key": "file_path", "type": "str", "description": "Path to file"}
    ]
}
```

## Warnings from the Trenches

### 1. The "Exclusive Params" Trap
```python
# CRITICAL: Params that are also inputs must be filtered!
inputs_set = set(metadata['inputs'])
exclusive_params = [p for p in metadata['params'] if p not in inputs_set]
```
This is from the knowledge base. Shared store inputs automatically work as param fallbacks. Don't list them twice.

### 2. Security: No eval(), Ever
Previous tasks emphasized: NEVER use `eval()` or `ast.literal_eval()` to parse structures. It's a security risk. Parse manually.

### 3. Graceful Degradation is Non-Negotiable
From Task 7: Real-world docstrings have errors. Your parser must:
- Extract what it can
- Log warnings for malformed sections
- Never crash the system
- Fall back to simple format if structure parsing fails

### 4. Unicode Support Comes Free
Python's regex handles Unicode automatically. Don't overthink internationalization.

## Key Code Locations You Must Study

1. **The Current Parser**: `src/pflow/registry/metadata_extractor.py`
   - Start with `_extract_list_section()` - this is your foundation
   - Look at `_extract_shared_keys()` for key extraction patterns
   - `_extract_params()` shows parameter parsing

2. **Current Test Patterns**: `tests/test_registry/test_metadata_extractor.py`
   - Shows all valid current formats
   - Has edge cases you must still support
   - Your tests go here

3. **Real Usage Examples**: `src/pflow/nodes/`
   - `file/read_file.py` - simple Interface format
   - `github/get_issue.py` - will need complex structure docs
   - These show what actually exists today

## Parsing Strategy That Won't Make You Cry

Based on all the analysis, here's the approach that avoids the pitfalls:

1. **Phase 1: Format Detection**
   ```python
   if ':' in line_after_shared_bracket:
       # New format with types
   else:
       # Old format, return simple list
   ```

2. **Phase 2: Type Extraction**
   - For simple types: extract everything after the colon
   - For structured types: note the type is 'dict' or 'list', prepare for indentation parsing

3. **Phase 3: Structure Parsing** (if type is dict/list)
   - Track indentation levels
   - Build nested structure based on indentation
   - Extract inline comments as descriptions

4. **Phase 4: Comment Extraction**
   - Everything after `#` is a description
   - Strip and store with the field

## The Exact Formats You're Supporting

### Simple Type (Inline)
```python
Reads: shared["file_path"]: str, shared["encoding"]: str
Writes: shared["content"]: str  # File contents
Params: timeout: int  # Timeout in seconds
```

### Complex Structure (Indented)
```python
Writes: shared["issue_data"]: dict
    - number: int  # Issue number (use for API calls)
    - state: str  # "open" or "closed"
    - user: dict  # Issue author
      - login: str  # GitHub username
      - id: int  # User ID
    - labels: list[dict]  # Array of labels
      - name: str  # Label text
      - color: str  # Hex color
```

### Mixed Format (Both on Same Node)
```python
Writes: shared["result"]: dict, shared["error"]: str
    # Only result has structure:
    - result:
      - success: bool
      - data: str
```

## Documentation You MUST Read

1. **The Complete Specification**: `.taskmaster/tasks/task_14/task-14-complete-specification.md`
   - Has all format examples
   - Shows the exact storage structure

2. **All Resolved Ambiguities**: `.taskmaster/tasks/task_14/14_ambiguities.md`
   - Every design decision explained
   - The "why" behind each choice

3. **Implementation Recommendations**: `.taskmaster/tasks/task_14/implementation-recommendations.md`
   - Specific technical guidance
   - Pitfalls to avoid

## Testing Strategy from Task 7

Test these cases IMMEDIATELY as you build:
1. Old format still works perfectly
2. New format with simple types
3. New format with nested structures
4. Mixed formats in same docstring
5. Malformed structures (indentation errors)
6. Missing colons, missing types
7. Unicode in descriptions
8. Empty Interface sections

## Performance Considerations

- Parsing happens at startup during registry scan
- Every node's docstring is parsed
- Keep it efficient but correct
- Cache compiled regex patterns

## What Success Looks Like

When you're done:
1. Old nodes work without changes
2. New format parses into rich objects
3. Structures are captured with full depth
4. Descriptions are extracted from comments
5. Graceful fallback for any parsing errors
6. Clear logging of what was extracted

## Final Critical Reminder

The context builder (Task 14.2) will consume your output. Think about what it needs:
- Clear type information
- Navigable structure format
- Helpful descriptions
- Backward compatibility

You're building the foundation that everything else depends on. The planner's ability to generate valid proxy mappings depends entirely on your parser working correctly.

---

**Remember**: Read the project context (`.taskmaster/tasks/task_14/project-context.md`) for domain understanding. This handoff provides the implementation-specific knowledge that took significant discovery time. (This document might contain information about the other subtasks, remember that you are only implementing subtask 14.1. Not any functionality that should be implemented in subtasks 14.2, 14.3, or 14.4)

Do not start implementing yet, read the project context then say that you are ready to begin.
