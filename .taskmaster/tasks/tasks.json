{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Create package setup and CLI entry point",
        "description": "Set up the pflow package structure with proper entry point configuration",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "details": "Create pyproject.toml with proper package configuration and CLI entry point for 'pflow' command. Ensure package installs correctly with 'pip install -e .' and the pflow command becomes available. Set up initial src/pflow/ directory structure. Configure package metadata (name, version, dependencies). This task ensures the CLI framework in Task 2 has a proper foundation. Reference: standard Python packaging practices.",
        "testStrategy": "Verify package installs correctly. Test that 'pflow' command is available after installation. Validate package structure follows Python standards."
      },
      {
        "id": 2,
        "title": "Set up basic CLI with click framework",
        "description": "Create the minimal CLI entry point with basic flag parsing",
        "status": "pending",
        "dependencies": [
          1
        ],
        "priority": "high",
        "details": "Create src/pflow/__init__.py and src/pflow/cli.py using click. Set up main entry point with @click.group() for command routing. Implement basic --key=value flag parsing that collects all flags into a dict (no complex categorization yet). Create minimal package structure: src/pflow/core/, src/pflow/nodes/. Support 'pflow run <workflow>' as primary command. Parse and collect CLI arguments without processing them. This is just the CLI skeleton - command implementations come in later tasks. Reference docs: architecture.md#5.1.3, cli-runtime.md",
        "testStrategy": "Write unit tests for CLI flag parsing with various input formats. Verify command routing works correctly. Test error handling for invalid commands. Include tests as part of implementation."
      },
      {
        "id": 3,
        "title": "Build comprehensive shell pipe integration",
        "description": "Implement full Unix pipe support for stdin/stdout handling and shell integration",
        "status": "pending",
        "dependencies": [
          2
        ],
        "priority": "high",
        "details": "Create src/pflow/core/shell_integration.py with comprehensive Unix pipe support. Implement stdin detection and reading when data is piped to pflow. Support streaming for large data (not just reading entire stdin at once). Handle stdout output for chaining pflow with other Unix tools. Implement proper exit code propagation and signal handling (Ctrl+C). When stdin is detected, populate shared['stdin'] automatically. Support both batch mode (fail fast) and interactive mode (prompt for missing data). Look at Simon Willison's 'llm' CLI source code for excellent pipe integration patterns. This enables: 'cat data.txt | pflow process >> output.txt'. Reference docs: shell-pipes.md, architecture.md#5.1.1",
        "testStrategy": "Test pipe detection, streaming support, signal handling, and integration with Unix tools. Write comprehensive tests for various pipe scenarios."
      },
      {
        "id": 4,
        "title": "Implement shared store validation utilities",
        "description": "Create validation functions for the shared store pattern without unnecessary wrapper classes",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "details": "Create src/pflow/core/validation.py with validation functions for the shared store pattern: validate_reserved_keys(shared) to check reserved keys like 'stdin', validate_natural_patterns(shared) to ensure natural key naming conventions. No wrapper class needed - pocketflow already provides the dict pattern, we just need validation utilities. Use plain functions that operate on the shared dict. Part of Phase 1 Core Infrastructure. Reference docs: shared-store.md",
        "testStrategy": "Write unit tests for validation functions with various shared dict scenarios and error cases. Test reserved key detection and natural pattern validation."
      },
      {
        "id": 5,
        "title": "Create NodeAwareSharedStore proxy",
        "description": "Implement the proxy pattern for transparent key mapping between nodes with incompatible interfaces",
        "status": "pending",
        "dependencies": [
          4
        ],
        "priority": "high",
        "details": "Create src/pflow/core/proxy.py with NodeAwareSharedStore class. IMPLEMENTATION NOTE: During implementation planning, choose between dict subclass vs wrapper class approach. Implement transparent key mapping with zero overhead when no mappings defined. Support input_mappings and output_mappings only (no nested mappings in MVP). Nodes should fail fast on missing required inputs. Integrate with pocketflow node execution pattern. Reference docs: shared-store.md#2, cli-runtime.md#3",
        "testStrategy": "Test direct access (no mapping), proxy mapping scenarios, and performance overhead measurement. Verify fail-fast behavior on missing inputs. Write comprehensive unit tests."
      },
      {
        "id": 6,
        "title": "Build context-aware CLI parameter resolution",
        "description": "Implement the CLI resolution system that routes flags to shared store or node parameters based on context",
        "status": "pending",
        "dependencies": [
          2,
          3
        ],
        "priority": "high",
        "details": "Create src/pflow/core/cli_resolver.py with simple functions: collect_flags(args) that gathers all --key=value flags into a dict. Keep implementation simple - in MVP, all processing happens in the planner. The main purpose is to collect flags and detect stdin (already handled by shell integration in Task 3). This task mainly provides the interface between CLI and planner. Reference docs: architecture.md#5.1.1, cli-runtime.md#7",
        "testStrategy": "Test flag collection with various formats. Verify integration with shell pipe detection from Task 3. Write unit tests for flag parsing."
      },
      {
        "id": 7,
        "title": "Create template variable substitution",
        "description": "Implement simple $variable replacement for accessing shared store values",
        "status": "pending",
        "dependencies": [
          4
        ],
        "priority": "high",
        "details": "Add to src/pflow/core/validation.py (already handling shared store validation). Add resolve_template(text, shared) function using regex to replace $variable with shared[variable]. Handle missing variables by raising clear error with variable name. Template syntax is simple: $var or ${var} for variable names with special chars. This is just string substitution, not a complex template engine. Used by planner to generate prompts and by runtime to resolve node parameters. Reference docs: architecture.md#5.1.2, shared-store.md",
        "testStrategy": "Test variable substitution with various syntax forms, missing variable detection, and error handling. Include edge cases like ${var}, escaped dollars, etc."
      },
      {
        "id": 8,
        "title": "Implement node discovery via filesystem scanning",
        "description": "Scan Python files to find pocketflow.Node subclasses and extract metadata",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "details": "Create src/pflow/registry/scanner.py with scan_for_nodes(directories) function. Use ast module or importlib to find all classes inheriting from pocketflow.Node (BaseNode). Extract basic metadata: node name, module path, docstring. Store results in simple dict or JSON file for fast access. No complex indexing needed - just a list of available nodes. Focus on src/pflow/nodes/ directory. This is not a package registry - just local filesystem scanning. Reference docs: registry.md",
        "testStrategy": "Test node discovery with mock node files, metadata extraction accuracy, and registry performance. Write tests for various node structures."
      },
      {
        "id": 9,
        "title": "Define JSON IR schema",
        "description": "Create the JSON schema for workflow intermediate representation",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "details": "Create src/pflow/core/ir_schema.py with Pydantic models or JSON Schema definitions. Define minimal IR structure: nodes[] with id, type, params; edges[] with from, to, action (default 'default'); start_node id; optional mappings{} for NodeAwareSharedStore proxy. Keep it simple - just enough to represent a workflow graph. Use standard JSON Schema for validation. Don't overengineer - we can extend later. Example: {'nodes': [{'id': 'n1', 'type': 'read-file', 'params': {'file_path': 'input.txt'}}], 'edges': [], 'start_node': 'n1'}. Reference docs: schemas.md, planner.md#10.1",
        "testStrategy": "Test schema validation with valid and invalid IR examples, verify all required fields, test edge cases. Write schema validation tests."
      },
      {
        "id": 10,
        "title": "Extract node metadata from docstrings",
        "description": "Parse node docstrings to understand inputs, outputs, and parameters",
        "status": "pending",
        "dependencies": [
          8
        ],
        "priority": "medium",
        "details": "Create src/pflow/registry/metadata_extractor.py with extract_metadata(node_class) function. Parse docstring to find: 1) Node description, 2) Interface section with inputs/outputs, 3) Which parameters go to shared store vs node.set_params(). Use simple regex or docstring_parser library. Output format: {'inputs': ['file_path'], 'outputs': ['content'], 'params': ['encoding']}. This metadata helps the planner understand how to connect nodes. Keep extraction logic simple - don't over-parse. Reference docs: metadata-extraction.md, planner.md#5.1",
        "testStrategy": "Test extraction from various docstring formats, parameter classification accuracy. Write tests with different docstring styles."
      },
      {
        "id": 11,
        "title": "Create registry CLI commands",
        "description": "Implement CLI commands for registry operations: list, describe, and search nodes",
        "status": "pending",
        "dependencies": [
          2,
          8,
          10
        ],
        "priority": "medium",
        "details": "Create src/pflow/cli/registry.py. Implement 'pflow registry list' showing individual platform nodes, 'pflow registry describe <node>' for detailed info with rich formatting for node-specific parameters. Part of enhanced registry infrastructure for fast lookups by node ID and capabilities. Reference docs: registry.md",
        "testStrategy": "Test CLI output formatting, search functionality, and error handling. Write integration tests for registry commands."
      },
      {
        "id": 12,
        "title": "Implement github-get-issue node",
        "description": "Create the first simple GitHub node for retrieving issue details",
        "status": "pending",
        "dependencies": [
          4,
          8
        ],
        "priority": "high",
        "details": "Create src/pflow/nodes/github/github_get_issue.py inheriting from pocketflow.BaseNode. Implement simple single-purpose node that reads issue_number and repo from shared store or params (check shared first, then params). Use PyGithub or requests for API calls. Natural interface: shared['repo'], shared['issue_number'] \u2192 shared['issue_data'], shared['issue_title']. Authentication via environment variables (GITHUB_TOKEN). Error handling for API failures and rate limits with clear error messages. Fail fast on missing required inputs. Part of Phase 3 Simple Platform Nodes. Reference docs: simple-nodes.md",
        "testStrategy": "Mock GitHub API responses, test parameter handling and error cases. Test fail-fast behavior on missing inputs. Write comprehensive unit tests."
      },
      {
        "id": 13,
        "title": "Implement claude-code super node",
        "description": "Create the comprehensive Claude Code node for AI-assisted development with project context",
        "status": "pending",
        "dependencies": [
          4,
          8
        ],
        "priority": "high",
        "details": "Create src/pflow/nodes/claude_code.py inheriting from pocketflow.BaseNode. Single powerful node with instruction-based interface for AI-assisted development with full project context and file system access. Complex prompt generation from planner templates with structured instructions. Integration with headless Claude Code CLI for workflow automation. Natural interface: shared['prompt'] \u2192 shared['code_report'] (comprehensive development report). Model selection and parameter handling. Part of two-tier AI approach. Reference docs: core-node-packages/claude-nodes.md",
        "testStrategy": "Mock Claude Code CLI responses, test template processing and output parsing. Test error handling and timeout scenarios."
      },
      {
        "id": 14,
        "title": "Implement general LLM node",
        "description": "Create the general-purpose LLM node for all text processing tasks",
        "status": "pending",
        "dependencies": [
          4,
          8
        ],
        "priority": "high",
        "details": "Create src/pflow/nodes/llm.py inheriting from pocketflow.BaseNode. Simple interface for general text processing. Natural interface: shared['prompt'] \u2192 shared['response']. Support multiple providers (Claude API, OpenAI). Smart exception to prevent prompt node proliferation. Reference docs: core-node-packages/llm-nodes.md, architecture.md#3.4",
        "testStrategy": "Mock LLM API responses, test different providers and parameter configurations. Test retry logic and error handling."
      },
      {
        "id": 15,
        "title": "Implement git-commit node",
        "description": "Create simple git node for committing changes",
        "status": "pending",
        "dependencies": [
          4,
          8
        ],
        "priority": "medium",
        "details": "Create src/pflow/nodes/git/git_commit.py inheriting from pocketflow.BaseNode. Simple node reading shared['message'] and optional shared['files']. Execute git commands with safety checks and confirmation prompts in interactive mode. Natural interface: shared['message'] \u2192 shared['commit_hash']. Fail fast on missing commit message. Each node focused on single git operation. Reference docs: simple-nodes.md",
        "testStrategy": "Mock git commands, test safety measures and error handling. Test both interactive and batch modes."
      },
      {
        "id": 16,
        "title": "Implement read-file and write-file nodes",
        "description": "Create basic file I/O nodes for reading and writing files",
        "status": "pending",
        "dependencies": [
          4,
          8
        ],
        "priority": "medium",
        "details": "Create file nodes in src/pflow/nodes/file/, all inheriting from pocketflow.BaseNode: read_file.py, write_file.py, copy_file.py, move_file.py, and delete_file.py. Simple interfaces: read-file uses shared['file_path'] \u2192 shared['content'], write-file uses shared['content'] + shared['file_path'], copy/move use shared['source_path'] + shared['dest_path'], delete uses shared['file_path']. Include safety checks for all destructive operations. Fail fast on missing required inputs. Natural interface pattern for file operations. Reference docs: simple-nodes.md",
        "testStrategy": "Test file operations, permission handling, and safety validations. Test fail-fast behavior. Write comprehensive unit tests."
      },
      {
        "id": 17,
        "title": "Create additional GitHub nodes",
        "description": "Implement remaining GitHub platform nodes: create-pr, list-prs, add-comment, merge-pr",
        "status": "pending",
        "dependencies": [
          12
        ],
        "priority": "low",
        "details": "Create GitHub nodes in src/pflow/nodes/github/, all inheriting from pocketflow.BaseNode: github_create_pr.py, github_list_prs.py, github_add_comment.py, and github_merge_pr.py. Each with focused single purpose and natural interfaces: shared['pr_title'], shared['pr_body'], shared['repo']. github_merge_pr includes safety checks and conflict handling with shared['pr_number'], shared['merge_method']. Reference docs: simple-nodes.md",
        "testStrategy": "Mock API responses for each operation, test error handling. Write unit tests for each node."
      },
      {
        "id": 18,
        "title": "Build CI and shell nodes",
        "description": "Create comprehensive set of CI and shell execution nodes",
        "status": "pending",
        "dependencies": [
          4,
          8
        ],
        "priority": "low",
        "details": "Create CI and shell nodes, all inheriting from pocketflow.BaseNode. CI nodes in src/pflow/nodes/ci/: ci_run_tests.py, ci_get_status.py, ci_trigger_build.py, ci_get_logs.py. Shell nodes in src/pflow/nodes/shell/: shell_exec.py, shell_pipe.py, shell_background.py. CI nodes use natural interface: shared['test_command'] \u2192 shared['test_results'], support multiple CI systems (GitHub Actions, Jenkins, local). Shell nodes use shared['command'] \u2192 shared['output'] with shell_background also writing shared['pid']. Auto-detect test frameworks, handle exit codes, timeout handling, and security considerations. Reference docs: simple-nodes.md",
        "testStrategy": "Mock test framework responses, test command execution and timeout handling. Write security-focused tests."
      },
      {
        "id": 19,
        "title": "Implement LLM API client",
        "description": "Create simple client for calling LLM APIs during planning",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "details": "Create src/pflow/planning/llm_client.py with simple functions: call_llm(prompt, model='claude-3-sonnet') that makes API calls to Claude or OpenAI. IMPLEMENTATION NOTE: Consider using Simon Willison's 'llm' package for simplified implementation and model flexibility. If using custom implementation: Use httpx or requests for API calls. Basic retry with exponential backoff (max 3 retries). Read API keys from environment variables. Return just the text response. Keep it simple - this is not a framework, just utility functions for the planner. Reference docs: planner.md#6.2",
        "testStrategy": "Mock LLM API calls, test retry logic and error handling. Test with different model providers."
      },
      {
        "id": 20,
        "title": "Create planning context builder",
        "description": "Format node metadata for LLM-based workflow planning",
        "status": "pending",
        "dependencies": [
          10
        ],
        "priority": "high",
        "details": "Create src/pflow/planning/context_builder.py with build_context(registry_metadata) function. Format node information into a structured text that LLMs can understand: node names, descriptions, inputs/outputs, parameter types. Keep format simple and readable - just markdown tables or structured text. Include which parameters go to shared store vs node.set_params(). This provides the LLM with available 'tools' for building workflows. Output example: 'Available nodes:\n- read-file: Reads file from disk\n  Inputs: file_path (from shared store)\n  Outputs: content (to shared store)'. Reference docs: planner.md#6.1",
        "testStrategy": "Test context generation, metadata optimization, and LLM readability. Verify output format is parseable."
      },
      {
        "id": 21,
        "title": "Implement workflow generation engine",
        "description": "Create the core engine that transforms natural language into template-driven workflows",
        "status": "pending",
        "dependencies": [
          7,
          9,
          19,
          20
        ],
        "priority": "high",
        "details": "Create src/pflow/planning/workflow_compiler.py with compile_request(user_input, node_context) function. Handles BOTH natural language (quoted: \"analyze this file\") AND CLI pipe syntax (unquoted: read-file >> llm). For MVP, route both through LLM which understands pipe syntax as domain-specific language. Use LLM to: 1) Parse intent from natural language OR interpret CLI syntax structure, 2) Select appropriate nodes, 3) Generate workflow with template variables like $issue_data, $code_report, 4) Fill in missing parameters and connections. The LLM generates template-driven prompts like: 'Fix the issue described in: $issue_data'. Examples: \"analyze error.log\" OR read-file --path=error.log >> llm both generate complete workflows. CLI syntax rarely specifies all parameters, so LLM fills gaps. Direct CLI parsing is v2.0 optimization. Reference docs: planner.md#6.1, workflow-analysis.md",
        "testStrategy": "Test workflow generation accuracy for both natural language and CLI syntax. Test template variable generation. Verify IR structure validity."
      },
      {
        "id": 22,
        "title": "Build workflow storage and approval system",
        "description": "Implement user verification and workflow persistence",
        "status": "pending",
        "dependencies": [
          21
        ],
        "priority": "medium",
        "details": "Create src/pflow/planning/approval.py and src/pflow/core/workflow_storage.py. Show generated CLI workflow for approval with clear presentation of individual node syntax. Allow parameter modifications before execution. Save approved workflows with meaningful names to ~/.pflow/workflows/. Implement pattern recognition for intelligent reuse of existing workflow definitions. Parameter extraction for similar requests to enable 'Plan Once, Run Forever' optimization. Target \u226590% user approval rate. Reference docs: planner.md#11",
        "testStrategy": "Test approval flow, workflow saving/loading, and modification handling. Test pattern matching for workflow reuse."
      },
      {
        "id": 23,
        "title": "Create IR compiler and runtime coordinator",
        "description": "Build the compiler that converts JSON IR to pocketflow.Flow objects with template resolution",
        "status": "pending",
        "dependencies": [
          5,
          7,
          8,
          9
        ],
        "priority": "high",
        "details": "Create src/pflow/runtime/compiler.py to convert JSON IR to executable code using pocketflow: compile_ir_to_flow(ir_json, shared) that instantiates nodes from registry, resolves template variables in params using resolve_template(), connects nodes with pocketflow's >> operator based on edges, returns pocketflow.Flow object. When mappings defined in IR, wrap shared store with NodeAwareSharedStore proxy. execute_with_tracing(flow, shared) wraps flow.run() with logging. Example: IR with read-file -> llm nodes becomes: node1 >> node2; flow = Flow(start=node1). DO NOT reimplement execution - just compile IR to pocketflow objects. Reference docs: architecture.md#5.4, runtime.md",
        "testStrategy": "End-to-end workflow execution tests with various node combinations. Test template resolution and proxy usage."
      },
      {
        "id": 24,
        "title": "Add IR and workflow validation",
        "description": "Validate JSON IR structure and node compatibility",
        "status": "pending",
        "dependencies": [
          4,
          9
        ],
        "priority": "high",
        "details": "Extend src/pflow/core/validation.py (from task 4) with IR validation functions: validate_ir(ir_json) to check JSON schema compliance, validate_node_compatibility(ir_json, registry) to ensure nodes exist and edges are valid, validate_templates(ir_json, initial_shared) to check all template variables can be resolved. Use jsonschema library for schema validation. Return clear error messages pointing to specific issues. This is not a complex framework - just validation functions that the planner and runtime call. Reference docs: planner.md#8, architecture.md#10.3",
        "testStrategy": "Test validation rules, error messages, and edge cases. Write comprehensive validation tests."
      },
      {
        "id": 25,
        "title": "Build caching system",
        "description": "Implement node-level caching for flow_safe nodes",
        "status": "pending",
        "dependencies": [
          23
        ],
        "priority": "medium",
        "details": "Create src/pflow/runtime/cache.py as optional performance optimization. Simple disk-based cache using pickle or json. Cache key = hash(node_type + params + inputs). Store in ~/.pflow/cache/. Only cache nodes marked as @flow_safe (deterministic). Start with just LLM nodes to save API costs. Can be disabled via --no-cache flag. This is not critical for MVP - implement only if performance becomes an issue. Reference docs: runtime.md#caching-strategy",
        "testStrategy": "Test cache hits/misses, key computation, and storage operations. Test cache invalidation."
      },
      {
        "id": 26,
        "title": "Create comprehensive test suite",
        "description": "Build integration tests for all components not covered by unit tests",
        "status": "pending",
        "dependencies": [
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          21,
          22,
          23,
          24,
          32,
          34
        ],
        "priority": "high",
        "details": "Create tests/ structure for integration and performance tests (unit tests already created with each task). Integration tests for end-to-end workflows. Performance benchmark suite in tests/benchmarks/ measuring planning latency (\u2264800ms target), execution speed (\u22642s overhead target), token usage optimization. Error recovery test suite in tests/error_recovery/ for invalid input handling, external service failures, partial execution scenarios. Mock external services. Test natural language \u2192 workflow generation with \u226595% success rate target.",
        "testStrategy": "Achieve >90% code coverage including integration scenarios. Test all critical paths and error scenarios."
      },
      {
        "id": 27,
        "title": "Polish CLI experience and documentation",
        "description": "Enhance user experience with better error messages, help text, and initial documentation",
        "status": "pending",
        "dependencies": [
          26
        ],
        "priority": "low",
        "details": "Improve error messages with actionable suggestions and clear next steps. Add comprehensive --help for all commands. Create initial README with quickstart guide showing primary workflow example (GitHub issue resolution). Update relevant documentation as features are implemented. Support developer workflow scenarios including slash command comparison (10x efficiency gain target). Reference docs: architecture.md#11.3",
        "testStrategy": "User acceptance testing, documentation review, error message clarity testing."
      },
      {
        "id": 28,
        "title": "[DEFER TO v2.0] Implement interface compatibility system",
        "description": "Create the compatibility analysis for shared store key matching and type validation between nodes",
        "status": "deferred",
        "dependencies": [
          4,
          5,
          10
        ],
        "priority": "low",
        "details": "[DEFERRED TO v2.0 - Not needed for MVP] Advanced compatibility checking is for marketplace scenarios. MVP nodes have compatible interfaces by design. Basic validation in task 24 is sufficient for MVP. When implemented in v2.0: Create compatibility analysis for heterogeneous node sources. Reference docs show this as post-MVP feature for complex marketplace integration.",
        "testStrategy": "Test interface matching scenarios, type validation edge cases, and proxy mapping generation"
      },
      {
        "id": 29,
        "title": "[DEFER TO v2.0] Build success metrics instrumentation",
        "description": "Implement comprehensive metrics tracking for planning success, execution reliability, and performance",
        "status": "deferred",
        "dependencies": [
          21,
          23
        ],
        "priority": "low",
        "details": "[DEFERRED TO v2.0 - Premature optimization] Focus on building working MVP first before instrumenting performance. Basic logging is sufficient for MVP. When implemented: Add lightweight metrics collection for key performance indicators. Can use simple timing decorators and counters initially. Reference docs: architecture.md#11 shows metrics as success criteria, not MVP feature.",
        "testStrategy": "Test metrics collection accuracy, performance overhead, and aggregation logic"
      },
      {
        "id": 30,
        "title": "Create prompt templates for planning",
        "description": "Design effective prompts for LLM-based workflow generation",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "details": "Create src/pflow/planning/prompts.py with prompt templates as simple string constants or functions. Include: 1) Workflow generation prompt with node context and examples, 2) Error recovery prompt for failed attempts, 3) Template variable extraction prompt. Emphasize template-driven prompt generation with $variable syntax. Use f-strings or jinja2 for template composition. Keep prompts focused and include concrete examples. Test prompts manually to ensure they generate valid JSON IR. Example structure: WORKFLOW_PROMPT = '''Given these nodes: {node_context}\nGenerate a workflow for: {user_request}\nOutput JSON IR format with template variables like $issue_data...'''. Reference docs: planner.md#6.1",
        "testStrategy": "Test prompt generation for various scenarios, template composition, and token optimization. Verify IR generation success rate."
      },
      {
        "id": 31,
        "title": "Implement additional git nodes",
        "description": "Create remaining git platform nodes: push, create-branch, merge, and status",
        "status": "pending",
        "dependencies": [
          15
        ],
        "priority": "low",
        "details": "Create git nodes in src/pflow/nodes/git/, all inheriting from pocketflow.BaseNode: git_push.py, git_create_branch.py, git_merge.py, and git_status.py. Each node follows simple single-purpose pattern: git-push reads shared['branch'] and executes push, git-create-branch reads shared['branch_name'] and creates branch, git-merge reads shared['source_branch'] and shared['target_branch'], git-status writes shared['git_status']. Include safety checks and confirmation prompts for destructive operations. Reference docs: simple-nodes.md",
        "testStrategy": "Mock git commands for each operation, test safety measures and edge cases. Write unit tests."
      },
      {
        "id": 32,
        "title": "Implement CLI autocomplete for node discovery",
        "description": "Add shell autocomplete for node names and parameters to enhance CLI usability",
        "status": "pending",
        "dependencies": [
          2,
          8,
          11
        ],
        "priority": "high",
        "details": "Create src/pflow/cli/autocomplete.py with shell completion support. Implement autocomplete for: node names (read-file, llm, github-get-issue), common parameters (--path, --prompt, --issue), pipe operator (>>). Use click's shell completion features. Generate completion scripts for bash/zsh/fish. When user types 'pflow read-f[TAB]', complete to 'read-file'. When typing 'pflow read-file --[TAB]', show available parameters from node metadata. This provides immediate value by helping users discover available nodes without documentation. Works even though CLI syntax is processed by LLM in MVP. Makes the tool feel responsive and professional. Reference docs: autocomplete.md (concepts), cli-runtime.md",
        "testStrategy": "Test completion generation, shell integration, and user experience across shells. Write integration tests."
      },
      {
        "id": 33,
        "title": "[DEFER TO v2.0] Implement direct CLI parsing without LLM",
        "description": "Parse CLI pipe syntax directly for minor performance optimization",
        "status": "deferred",
        "dependencies": [
          21,
          32
        ],
        "priority": "low",
        "details": "[DEFERRED TO v2.0 - Minor optimization only] Create direct parser for CLI pipe syntax that bypasses LLM for fully-specified commands. Parse 'node1 --param=value >> node2' syntax directly into IR. Even with direct parsing, LLM still needed for: missing parameters, template variables, data flow connections, shared store mappings. This is a minor optimization since users rarely specify everything. Benefits: slightly faster for complete commands, more predictable for simple flows, reduced token usage. The high-value feature is autocomplete (task #32), not direct parsing. Reference docs: planner.md#3.2 (future state)",
        "testStrategy": "Test parsing accuracy, measure actual performance improvement, ensure LLM fallback works"
      },
      {
        "id": 34,
        "title": "Implement execution tracing system",
        "description": "Build comprehensive execution visibility for debugging and optimization",
        "status": "pending",
        "dependencies": [
          23
        ],
        "priority": "high",
        "details": "Create src/pflow/runtime/tracing.py with execution tracing that helps users understand, debug, and optimize execution flow. Capture and display: inputs/outputs for each node, shared state diffs per step, LLM tokens used per node and total, execution time per node, cache hits/misses. Format output clearly with proper error context: '[1] read-file (0.02s) Input: {file_path: 'data.txt'} Output: {content: '...'} Shared Store \u0394: +content'. Support different verbosity levels via --trace flag. Include cost estimation for LLM nodes ($0.0012 per call). Critical for understanding workflow behavior and optimizing performance. Reference docs: architecture.md (observability), runtime.md",
        "testStrategy": "Test trace output formatting, performance overhead, and debugging effectiveness. Verify error context is clear."
      },
      {
        "id": 35,
        "title": "Create MVP validation test suite",
        "description": "End-to-end validation that MVP meets all acceptance criteria",
        "status": "pending",
        "dependencies": [
          26
        ],
        "priority": "high",
        "details": "Create tests/mvp_validation/ with end-to-end scenarios proving real value. Test core workflow: 'pflow \"fix github issue 123\"' generates appropriate workflow, executes successfully, creates PR with fix. Measure against MVP criteria: 10x faster than manual LLM interaction, natural language to workflow works, template resolution functions correctly, all platform nodes integrate properly. Include performance benchmarks showing planning \u2264800ms, execution overhead \u22642s. Document which v2.0 features are intentionally excluded. This is about proving the MVP delivers its core value proposition. Reference docs: mvp-scope.md, architecture.md#11",
        "testStrategy": "Test real-world scenarios, measure performance targets, validate user experience metrics."
      },
      {
        "id": 36,
        "title": "[DEFER TO v2.0] Support nested proxy mappings",
        "description": "Implement complex key mapping patterns for advanced node compatibility",
        "status": "deferred",
        "dependencies": [
          5
        ],
        "priority": "low",
        "details": "[DEFERRED TO v2.0 - Not needed for MVP] Support for nested mappings like 'data.content' -> 'file_data.text'. MVP uses simple key-to-key mappings only. This feature enables more complex node compatibility patterns but adds significant complexity. When implemented: extend NodeAwareSharedStore to handle dot-notation paths and nested object transformations.",
        "testStrategy": "Test nested mapping scenarios, performance impact, and edge cases with deep nesting."
      }
    ],
    "metadata": {
      "created": "2025-06-18T20:41:12.050Z",
      "updated": "2025-06-24T10:00:00.000Z",
      "description": "Refined task list for pflow MVP implementation with proper sequencing and dependencies"
    }
  }
}
