{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Create package setup and CLI entry point",
        "description": "Set up the pflow package structure with proper entry point configuration",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "details": "Create pyproject.toml with proper package configuration and CLI entry point for 'pflow' command. Ensure package installs correctly with 'pip install -e .' and the pflow command becomes available. Set up initial src/pflow/ directory structure. Configure package metadata (name, version, dependencies). This task ensures the CLI framework in Task 2 has a proper foundation. Reference: standard Python packaging practices.",
        "testStrategy": "Verify package installs correctly. Test that 'pflow' command is available after installation. Validate package structure follows Python standards.",
        "subtasks": [
          {
            "id": 1,
            "title": "Configure CLI entry point in pyproject.toml",
            "description": "Add [project.scripts] section to pyproject.toml defining 'pflow = \"pflow.cli:main\"' as the console script entry point. This enables the 'pflow' command to be available system-wide after installation.",
            "dependencies": [],
            "details": "Edit pyproject.toml to add the [project.scripts] section with the pflow entry point. This follows standard Python packaging practices for creating command-line tools. The entry point syntax 'pflow.cli:main' tells setuptools to look for a 'main' function in the pflow.cli module when the 'pflow' command is invoked.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Create CLI module structure with basic click application",
            "description": "Create the src/pflow/cli/ directory structure with __init__.py and main.py files. Implement a basic click application in main.py with a simple test command to verify the framework is working.",
            "dependencies": [
              1
            ],
            "details": "Create src/pflow/cli/__init__.py (can be empty initially) and src/pflow/cli/main.py containing a basic click application. The main.py should define a main() function decorated with @click.command() or @click.group() and include at least one simple command (e.g., 'version' or 'hello') to test the CLI framework. This provides the actual CLI code that the pyproject.toml entry point references.",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Verify package installation and CLI availability",
            "description": "Install the package in development mode using 'pip install -e .' and verify that the 'pflow' command becomes available in the terminal. Add a basic test to ensure the CLI framework is properly initialized.",
            "dependencies": [
              2
            ],
            "details": "Run 'pip install -e .' (or 'uv pip install -e .') in the project root to install the package in editable/development mode. Verify the 'pflow' command is available by running it in the terminal and checking it executes without errors. Create a basic test in tests/test_cli.py using click.testing.CliRunner to ensure the CLI framework initializes correctly and the test command works as expected. This confirms the entire setup chain from pyproject.toml entry point to CLI execution is functioning properly.",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 2,
        "title": "Set up basic CLI for argument collection",
        "description": "Create the minimal CLI entry point with basic flag parsing",
        "status": "done",
        "dependencies": [
          1
        ],
        "priority": "high",
        "details": "Create src/pflow/cli.py using click. The primary goal is to accept and collect all command-line arguments (e.g., 'node1 --param=val => node2') as a raw list or string. This raw input will be passed to the planner (in Phase 3) or a simple dispatcher. **This task does NOT involve parsing the '=>' operator or interpreting node syntax.** It only provides the entry point and collects the user's raw input.",
        "testStrategy": "Create tests/test_cli_core.py. Use click.testing.CliRunner to test basic command invocation (e.g., pflow --version). Verify the --help output is complete. Test that a simple dummy command receives its arguments correctly. Test error handling for both unknown arguments and invalid option formats to ensure the CLI is robust.",
        "subtasks": [
          {
            "id": 1,
            "title": "Create 'run' subcommand with basic argument collection",
            "description": "Add a 'run' subcommand to the existing click.group() in src/pflow/cli/main.py that collects all command-line arguments as raw input using click's nargs=-1 feature, preserving special operators like '>>'",
            "dependencies": [],
            "details": "Implementation: Add @main.command() decorator for 'run' subcommand, use @click.argument('workflow', nargs=-1) to collect all args as a tuple, join arguments into a single string to preserve original input including '>>' operators. Add basic docstring explaining the command's purpose. Temporarily print collected arguments for verification during development. Reference docs/reference/cli-reference.md for expected CLI behavior patterns.",
            "status": "done",
            "testStrategy": "Create initial tests in tests/test_cli_core.py: Test that 'pflow run' command exists and is callable using CliRunner, test argument collection with simple node names, verify preservation of '>>' operator in collected args, test handling of empty arguments"
          },
          {
            "id": 2,
            "title": "Implement proper input handling for various formats",
            "description": "Enhance the 'run' command to handle different input formats including quoted natural language commands, unquoted CLI syntax with flags, stdin piped input, and file-based input via --file option",
            "dependencies": [],
            "details": "Implementation: Detect stdin input using sys.stdin.isatty() and read piped content when available. Handle both quoted strings (\"plan something\") and unquoted syntax with proper flag preservation. Store raw input in click context using ctx.obj dictionary for future planner use. Add --file option using @click.option() to read workflow from file. Reference docs/features/cli-runtime.md for context storage patterns and argument flow.",
            "status": "done",
            "testStrategy": "Expand tests/test_cli_core.py: Test quoted natural language input collection, test unquoted CLI syntax with flags (--param=value), test stdin pipe detection and reading using mock stdin, test file input option with temporary files, verify context properly stores the raw input"
          },
          {
            "id": 3,
            "title": "Add comprehensive error handling and help text",
            "description": "Polish the CLI with proper error handling, informative help text following Unix conventions, user-friendly error messages, and appropriate exit codes",
            "dependencies": [
              2
            ],
            "details": "Implementation: Add detailed help text for the main command with usage examples showing various input formats. Implement error handling for invalid arguments with clear error messages. Use proper exit codes (0 for success, non-zero for errors). Ensure --help works properly. Add examples to help text demonstrating: simple node chains using => operator, natural language in quotes, piped input, file input. Reference docs/architecture/architecture.md#5.1 for 'Type flags; engine decides' philosophy.",
            "status": "done",
            "testStrategy": "Complete tests/test_cli_core.py coverage: Test help text displays correctly with expected examples, test error handling for malformed input with appropriate error messages, test proper exit codes for success/failure scenarios, verify error messages are clear and actionable"
          }
        ]
      },
      {
        "id": 3,
        "title": "Execute a Hardcoded 'Hello World' Workflow",
        "description": "Review and polish the implemented 'read-file => write-file' workflow execution system, ensuring all components are properly integrated and tested.",
        "status": "done",
        "dependencies": [
          6,
          11
        ],
        "priority": "high",
        "details": "This task has been substantially implemented (commit dff02c3). The core workflow execution pipeline is functional with: 1. A working 'hello_workflow.json' file that conforms to the IR schema. 2. Implemented 'read-file' and 'write-file' nodes inheriting from pocketflow.BaseNode. 3. The 'pflow --file <file.json>' command integrated into the CLI. 4. IR-to-Flow Converter integration for JSON to pocketflow.Flow conversion. 5. Shared store initialization and flow execution. Focus now shifts to review, polish, and ensuring completeness of the implementation.",
        "testStrategy": "Review existing tests/test_e2e_workflow.py for completeness. Verify all edge cases are covered. Ensure mock nodes properly test shared store behavior. Validate temporary file handling. Review test coverage for the execution pipeline.",
        "subtasks": [
          {
            "id": 1,
            "title": "Review and Document Existing Workflow Implementation",
            "description": "Thoroughly review the implemented workflow execution system to understand current state, identify any gaps, and document the implementation for future reference.",
            "status": "done",
            "dependencies": [],
            "details": "Review src/pflow/cli/main.py for JSON workflow processing implementation. Examine how validation \u2192 registry \u2192 compiler \u2192 execution pipeline is integrated. Document the shared store initialization and flow execution logic. Review hello_workflow.json structure and verify it follows IR schema. Check how 'default' and 'error' action results are handled. Create or update documentation for the workflow execution system.\n<info added on 2025-07-08T11:57:48.174Z>\nExamine the existing workflow execution implementation in src/pflow/cli/main.py (lines 80-88) to ensure it properly handles all edge cases. Verify that the try-except block catches all potential exceptions from validation, registry loading, compilation, and execution phases. Check that error messages are informative and user-friendly. Ensure the shared store is properly initialized before execution and cleaned up afterwards to prevent memory leaks. Review the flow execution result handling to confirm both successful and error outcomes are properly processed. Verify that the execution pipeline gracefully handles missing nodes, invalid action strings, and malformed workflow JSON. Test edge cases such as empty workflows, workflows with no nodes, and workflows with circular dependencies. Ensure proper logging is in place for debugging workflow execution issues. Consider adding execution timing or performance metrics if not already present. Validate that the hello_workflow.json execution path represents typical usage patterns and that the implementation generalizes well to other workflow types.\n</info added on 2025-07-08T11:57:48.174Z>",
            "testStrategy": "Review existing test coverage in test_e2e_workflow.py. Identify any missing test scenarios. Verify documentation accurately reflects implementation."
          },
          {
            "id": 2,
            "title": "Enhance Error Handling and User Feedback",
            "description": "Review and improve error handling throughout the execution pipeline, ensuring clear and actionable error messages for all failure modes.",
            "status": "done",
            "dependencies": [
              1
            ],
            "details": "Audit existing error handling in the execution pipeline. Verify helpful error messages exist for: missing registry (with populate instructions), JSON parsing errors, node not found errors, compilation failures, and execution errors. Review structured logging implementation for phase tracking. Ensure progress indicators work for long-running workflows. Verify patterns from knowledge/patterns.md are followed.\n<info added on 2025-07-08T11:58:06.787Z>\nExamined the current error handling implementation across the codebase. The CLI has basic error handling for common scenarios like missing registry files, invalid JSON, and validation errors. Error messages generally provide clear context but could be more actionable in some cases. Missing error scenarios identified: node execution failures with specific error types, partial workflow failures where some nodes succeed before failure occurs, and timeout scenarios for long-running nodes. Progress indicators are minimal - only basic print statements exist for workflow start/end. Consider adding: spinner or progress bar for long-running nodes, real-time status updates during execution, and clear phase indicators (compilation vs execution). All error handling should follow the established pattern of providing context, the specific error, and actionable next steps for the user.\n</info added on 2025-07-08T11:58:06.787Z>",
            "testStrategy": "Review error scenario tests. Add tests for any uncovered error paths. Verify error messages provide actionable guidance. Test logging includes proper phase information."
          },
          {
            "id": 3,
            "title": "Complete Integration Test Coverage and Polish and Optimize Implementation",
            "description": "Review and enhance the integration tests to ensure comprehensive coverage of all workflow execution scenarios also apply final polish to the workflow execution system based on review findings, optimizing for performance and maintainability.",
            "status": "done",
            "dependencies": [
              2
            ],
            "details": "Audit tests/test_e2e_workflow.py for coverage gaps. Verify tests exist for: complete workflow execution, file I/O operations, shared store state verification, error scenarios (missing files, invalid JSON, missing nodes), and retry behavior. Add any missing test scenarios identified during review. Ensure temporary file handling is properly tested. Verify line numbering behavior from ReadFileNode is tested.\n<info added on 2025-07-08T11:58:27.991Z>\nReview existing test coverage in tests/test_e2e_workflow.py to ensure completeness. Tests already exist for workflow execution, missing registry, invalid JSON, and validation errors. Additional areas to verify and enhance:\n\n- File I/O error handling (permissions, non-existent paths, disk full scenarios)\n- Shared store state persistence and isolation between workflow runs\n- Node execution order and dependency management\n- Retry mechanism with different failure types (transient vs permanent failures)\n- Edge cases: empty workflows, circular dependencies, malformed node configurations\n- Resource cleanup after workflow completion or failure\n- Concurrent workflow execution isolation\n- Memory management for large file operations\n- Timeout handling for long-running nodes\n- Line numbering preservation in ReadFileNode output\n- Error propagation through multi-node workflows\n- Validation of node input/output contracts\n\nEnsure each test clearly documents its purpose and expected behavior. Add parametrized tests where appropriate to cover multiple scenarios efficiently.\n</info added on 2025-07-08T11:58:27.991Z> Address any issues identified during review. Optimize performance bottlenecks if found. Ensure code follows project conventions and patterns. Update any outdated comments or documentation. Verify the implementation aligns with MVP scope defined in docs. Consider adding helpful CLI output formatting for better user experience",
            "testStrategy": "Run existing tests and analyze coverage report. Add tests for any uncovered paths. Ensure all major user scenarios are tested end-to-end. Performance benchmarks for workflow execution. Regression tests after optimizations. Manual testing of user experience improvements"
          }
        ]
      },
      {
        "id": 4,
        "title": "Implement IR-to-PocketFlow Object Converter",
        "description": "Build the compiler that converts JSON IR to pocketflow.Flow objects with template resolution",
        "status": "done",
        "dependencies": [
          6,
          5
        ],
        "priority": "high",
        "details": "Create src/pflow/runtime/compiler.py with compile_ir_to_flow(ir_json, registry) function. This function converts JSON IR to executable pocketflow.Flow objects. CRITICAL: The registry provides metadata ONLY (module path, class name) - NOT class references. Implementation: 1) Parse and validate IR JSON. 2) For each node in IR, look up metadata in registry (from Task 5). 3) Use importlib.import_module(registry[node_type]['module']) to dynamically import node modules. 4) Use getattr(module, registry[node_type]['class_name']) to get node class. 5) Verify the class inherits from pocketflow.BaseNode. 6) Instantiate nodes and set parameters. 7) Connect nodes using pocketflow's >> operator based on edges. 8) Return complete Flow object. Include proper error handling for missing nodes, import failures, and invalid IR. Handle ImportError and AttributeError with clear messages. Reference: pflow-pocketflow-integration-guide.md. This is a medium complexity task with multiple discrete steps but straightforward transformation logic.",
        "testStrategy": "Test IR parsing and validation, dynamic module importing from registry metadata (NOT class references), BaseNode inheritance verification, node instantiation with proper error messages, flow construction with >> operator, handling of missing nodes in registry, import errors (ImportError, AttributeError), and invalid IR structures. Mock importlib for testing without real node files. Verify the converter produces valid, executable pocketflow.Flow objects.",
        "subtasks": [
          {
            "id": 1,
            "title": "Create Compiler Foundation with IR Loading",
            "description": "Set up the compiler module structure in src/pflow/runtime/compiler.py and implement IR loading with basic validation. Handle both dict and JSON string inputs, verify basic structure (nodes/edges arrays), and create custom CompilationError exception class.",
            "dependencies": [],
            "details": "Create compile_ir_to_flow(ir_json, registry) function signature. Implement JSON parsing for string inputs and pass-through for dict inputs. Verify 'nodes' and 'edges' keys exist in IR. Create CompilationError class that includes context (node_id, node_type). Set up structured logging for debugging compilation steps. Focus on establishing the foundation without implementing actual compilation logic.\n<info added on 2025-06-29T17:06:19.629Z>\nTest Strategy:\n- Create tests/test_compiler_foundation.py as the primary test file\n- Test IR loading functionality with both valid JSON strings and dict objects using pytest\n- Implement error handling tests for malformed JSON (should raise JSONDecodeError) and missing required keys ('nodes', 'edges')\n- Verify CompilationError class includes proper context attributes (node_id, node_type) when raised\n- Test that structured logging is properly configured and captures compilation steps\n- Mock the actual compilation logic to test the foundation components independently without dependencies on node implementation\n</info added on 2025-06-29T17:06:19.629Z>",
            "status": "done",
            "testStrategy": "Test IR loading with valid JSON strings and dicts. Test error handling for malformed JSON and missing required keys. Verify CompilationError includes proper context. Mock actual compilation logic to test the foundation independently."
          },
          {
            "id": 2,
            "title": "Implement Dynamic Node Import System",
            "description": "Build the core dynamic import functionality that loads node classes from registry metadata using importlib. For each node type in the IR, look up metadata in registry, dynamically import the module, get the class reference, and verify it inherits from pocketflow.BaseNode.",
            "dependencies": [
              1
            ],
            "details": "Create helper function import_node_class(node_type, registry) that: 1) Looks up registry[node_type] for module/class_name, 2) Uses importlib.import_module() to load module, 3) Uses getattr() to get class reference, 4) Verifies inheritance with issubclass(cls, pocketflow.BaseNode). Handle ImportError (module not found), AttributeError (class not found), TypeError (wrong inheritance). Include rich error messages with node context.\n<info added on 2025-06-29T17:06:43.798Z>\nTest Strategy:\n- Create tests/test_dynamic_imports.py with comprehensive test coverage\n- Mock importlib.import_module to simulate various failure scenarios without requiring real imports\n- Test successful import scenarios using mock modules that contain proper BaseNode subclasses\n- Test error handling for ImportError when modules are not found\n- Test error handling for AttributeError when specified classes don't exist in the module\n- Test error handling for TypeError when classes don't inherit from BaseNode\n- Use actual test nodes from Task 5's src/pflow/nodes/test_node.py for integration testing to ensure real-world compatibility\n- Verify that all error messages include complete context: node ID, node type, module path, and the specific error that occurred\n- Test that the issubclass check properly validates BaseNode inheritance and rejects invalid classes\n</info added on 2025-06-29T17:06:43.798Z>",
            "status": "done",
            "testStrategy": "Mock importlib.import_module to test various failure scenarios. Test with actual test nodes from Task 5 registry. Verify inheritance checking catches non-BaseNode classes. Test error messages include proper context (node ID, type, specific failure reason)."
          },
          {
            "id": 3,
            "title": "Build Flow Construction and Wiring",
            "description": "Implement node instantiation from imported classes, parameter setting using set_params(), and flow wiring using PocketFlow's >> operator based on edges array. Handle both default connections and action-based routing.",
            "dependencies": [
              2
            ],
            "details": "Store instantiated nodes in dict keyed by node_id. For each node: instantiate using imported class, call set_params() if params exist (pass template vars like $var unchanged). For edges: use >> for action='default', use - operator for named actions. Identify start_node (first in nodes array if not specified). Create pocketflow.Flow object with connected nodes. Add debug logging for each connection made.\n<info added on 2025-06-29T17:07:03.637Z>\nTest Strategy:\n- Create tests/test_flow_construction.py\n- Test simple linear flows (A >> B >> C) using mock nodes\n- Test action-based routing (A - 'error' >> B, A - 'success' >> C)\n- Test parameter passing with set_params() including template variables like $var\n- Test that template variables are passed unchanged (no resolution at compile time)\n- Test invalid edge references (non-existent node IDs) raise clear errors\n- Test start_node detection (explicit vs first node fallback)\n- Verify the resulting Flow object has correct structure and can be executed\n- Use pocketflow's test utilities if available\n</info added on 2025-06-29T17:07:03.637Z>",
            "status": "done",
            "testStrategy": "Test simple linear flows (A >> B >> C). Test action-based routing (A - 'success' >> B). Test parameter passing including template variables. Test invalid edge references raise clear errors. Verify Flow object is properly constructed."
          },
          {
            "id": 4,
            "title": "Add Integration Tests and Polish",
            "description": "Create comprehensive integration tests using real IR examples and mock nodes. Improve error messages based on test scenarios, ensure performance targets are met, and add documentation.",
            "dependencies": [
              3
            ],
            "details": "Create integration tests that compile actual IR examples from examples/ directory. Test end-to-end with mock nodes that inherit from BaseNode. Ensure compilation time < 100ms for typical workflows. Polish error messages to be actionable (include suggestions for fixes). Add docstrings and inline comments explaining the compilation process. Verify all code follows project conventions (type hints, error handling patterns).\n<info added on 2025-06-29T17:07:35.672Z>\nTest Strategy:\n- Create tests/test_compiler_integration.py for comprehensive end-to-end testing\n- Load actual IR examples from examples/ directory (create directory with sample IR files if it doesn't exist)\n- Implement mock nodes that inherit from pocketflow.BaseNode to test compilation without real node implementations\n- Add performance benchmarking to ensure compilation completes in < 100ms for typical 5-10 node workflows\n- Test error message quality with assertions that error messages include actionable suggestions (e.g., 'Node type \"llm\" not found in registry. Did you mean \"llm-node\"?')\n- Integrate with actual registry implementation from Task 5 to verify real-world compatibility\n- Create smoke test that compiles and executes a simple flow end-to-end to validate the entire pipeline\n- Document performance benchmarks in test comments for future regression tracking\n- Ensure 95%+ code coverage across all compiler modules (use pytest-cov to measure and enforce)\n</info added on 2025-06-29T17:07:35.672Z>",
            "status": "done",
            "testStrategy": "Integration tests with complete IR->Flow compilation. Performance tests measuring compilation time. Error scenario tests covering all failure modes. Test with actual registry from Task 5. Verify compiled flows can be executed (smoke test)."
          }
        ]
      },
      {
        "id": 5,
        "title": "Implement node discovery via filesystem scanning",
        "description": "Scan Python files to find pocketflow.BaseNode subclasses and extract metadata",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "details": "Create src/pflow/registry/scanner.py with scan_for_nodes(directories) function. Use importlib to find all classes inheriting from pocketflow.BaseNode (CRITICAL: NOT pocketflow.Node). Add security note about importlib executing code on import. For MVP, only scan package nodes: Path(pflow.__file__).parent / 'nodes'. Extract basic metadata ONLY: 1) module (full import path), 2) class_name, 3) name (from class.name attribute or kebab-case fallback), 4) docstring (raw text, NOT parsed), 5) file_path. Store in persistent JSON file at ~/.pflow/registry.json. Node naming: Check for explicit 'name' class attribute first, fallback to converting ClassName to kebab-case (e.g., ReadFileNode \u2192 read-file). Output format: {'read-file': {'module': 'pflow.nodes.file.read_file', 'class_name': 'ReadFileNode', 'docstring': '...', 'file_path': '/path/to/file.py'}}. IMPORTANT: Registry stores metadata ONLY, not class references. Components using the registry must use dynamic imports. Create test node (src/pflow/nodes/test_node.py) inheriting from BaseNode with Interface docstring. Reference: registry.md, metadata-extraction.md",
        "testStrategy": "Test node discovery with real and mock node files, verify BaseNode inheritance detection, test name extraction (both explicit attribute and kebab-case conversion), verify registry JSON persistence and loading, test with various node structures and edge cases (no docstring, no name attribute, multiple inheritance). Mock importlib where needed to avoid executing untrusted code. Ensure scanner correctly identifies only BaseNode subclasses and ignores other classes.",
        "subtasks": [
          {
            "id": 1,
            "title": "Create test node and implement core scanner",
            "description": "Set up the nodes directory structure with a test node that subclasses pocketflow.BaseNode, then implement the core filesystem scanning logic in src/pflow/planning/scanner.py to recursively find Python files and identify BaseNode subclasses",
            "dependencies": [],
            "details": "Create src/pflow/nodes/ directory if it doesn't exist. Create src/pflow/nodes/test_node.py with a simple BaseNode subclass for testing. Implement src/pflow/planning/scanner.py with scan_directory() function that uses ast module to parse Python files and identify classes that inherit from pocketflow.BaseNode. The scanner should handle import variations (from pocketflow import BaseNode, import pocketflow, etc.) and return a list of discovered node classes with their file paths.\n<info added on 2025-06-29T08:38:20.409Z>\nImplementation location and approach changes:\n- Create src/pflow/registry/scanner.py instead of src/pflow/planning/scanner.py\n- Implement scan_for_nodes(directories) function that accepts a list of directory paths\n- Use importlib.import_module() to dynamically import Python modules from the discovered files\n- Add security warning comment that importlib executes module code on import\n- Use inspect.isclass() to check if objects are classes and issubclass() to verify BaseNode inheritance\n- The function should iterate through directories, find .py files, convert file paths to module names, import them dynamically, and inspect their contents for BaseNode subclasses\n</info added on 2025-06-29T08:38:20.409Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 2,
            "title": "Implement metadata extraction and persistence",
            "description": "Extract metadata from discovered BaseNode subclasses including class name, docstring, method signatures, and file location, then implement persistence to ~/.pflow/registry.json with proper serialization",
            "dependencies": [
              1
            ],
            "details": "Extend the scanner to extract metadata from each discovered node: class name, docstring, prep/exec/post method signatures, file path, and last modified time. Create a Registry class that manages the discovered nodes and handles persistence to ~/.pflow/registry.json. Implement load() and save() methods with proper JSON serialization. Ensure the registry directory (~/.pflow/) is created if it doesn't exist. Handle cases where nodes might not have all three methods (prep/exec/post).\n<info added on 2025-06-29T08:38:36.558Z>\nThe scanner should extract only the following basic metadata from each discovered node:\n- module: The full import path (e.g., 'pflow.nodes.file.read_file')\n- class_name: The class name (e.g., 'ReadFileNode')\n- name: From the class's name attribute, or derive from class name using kebab-case conversion as fallback\n- docstring: The raw docstring text without any parsing or processing\n- file_path: The filesystem path to the node file\n\nThe Registry class should store nodes in a dictionary format with the node name as the key, mapping to the metadata dictionary. Method signatures and last modified timestamps should not be extracted or stored.\n</info added on 2025-06-29T08:38:36.558Z>",
            "status": "done",
            "testStrategy": ""
          },
          {
            "id": 3,
            "title": "Add comprehensive tests",
            "description": "Write thorough unit tests for the scanner and registry functionality covering various edge cases, malformed nodes, and filesystem scenarios",
            "dependencies": [
              1,
              2
            ],
            "details": "Create tests/test_scanner.py with test cases for: scanning directories with valid nodes, handling Python files without BaseNode subclasses, dealing with syntax errors in Python files, testing various import patterns (from/import/as), verifying metadata extraction accuracy. Create tests/test_registry.py to test: registry persistence and loading, handling corrupted registry files, registry updates when nodes change, proper JSON serialization of metadata. Include edge cases like empty directories, non-Python files, circular imports, and nodes with missing or malformed methods.\n<info added on 2025-06-29T08:39:00.507Z>\nThe tests should mock importlib operations for module loading and inspection rather than using AST parsing. Key test areas include:\n\nBaseNode inheritance detection tests to verify that only classes inheriting from pflow's BaseNode (not pocketflow.Node) are identified as valid nodes. This includes testing multiple inheritance scenarios and ensuring non-BaseNode classes are properly excluded.\n\nNode name extraction tests covering both explicit name attributes (class.name = \"my-node\") and automatic kebab-case conversion from class names (MyComplexNode -> \"my-complex-node\"). Edge cases should include names with numbers, acronyms, and special Python naming patterns.\n\nRegistry JSON format validation ensuring the output structure uses node names as top-level keys mapping to metadata objects. Tests should verify proper serialization of all metadata fields and handle edge cases like duplicate node names.\n\nSecurity warning verification to confirm that generated registry files include appropriate comments warning against untrusted node execution. The test should check for the presence and correct formatting of security disclaimers in the JSON output.\n\nMock-based testing approach should simulate various importlib scenarios including import failures, missing dependencies, and successful module loading without executing actual node code during discovery.\n</info added on 2025-06-29T08:39:00.507Z>",
            "status": "done",
            "testStrategy": ""
          }
        ]
      },
      {
        "id": 6,
        "title": "Define JSON IR schema",
        "description": "Create the JSON schema for workflow intermediate representation",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "details": "Create src/pflow/core/ir_schema.py with JSON Schema definitions. Define minimal IR structure: nodes[] with id, type, params; edges[] with from, to, action (default 'default'); start_node id; optional mappings{} for NodeAwareSharedStore proxy. Keep it simple - just enough to represent a workflow graph. Use standard JSON Schema for validation. Don't overengineer - we can extend later. Example: {'nodes': [{'id': 'n1', 'type': 'read-file', 'params': {'file_path': 'input.txt'}}], 'edges': [], 'start_node': 'n1'}. Reference docs: schemas.md, planner.md#10.1",
        "testStrategy": "Test schema validation with valid and invalid IR examples, verify all required fields, test edge cases. Write schema validation tests.",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Core JSON Schema Structure",
            "description": "Create the foundational JSON schema definitions for workflow IR in src/pflow/core/ir_schema.py. Define the minimal IR structure including nodes array (with id, type, params), edges array (with from, to, action), start_node, and optional mappings. Use standard JSON Schema Draft 7 format following the decisions in the research files.",
            "dependencies": [],
            "details": "Create src/pflow/core/__init__.py and src/pflow/core/ir_schema.py. Define schema as Python dictionary using JSON Schema Draft 7 format. Include minimal envelope with schema version for future compatibility. Use 'type' field for nodes (not 'registry_id') per task example. Make start_node optional with sensible default behavior. Include optional action field in edges with 'default' as default value. Define mappings structure for proxy pattern support. Write initial validation tests alongside implementation.",
            "status": "done",
            "testStrategy": "Test valid minimal IR (single node, no edges). Test valid complex IR (multiple nodes with edges). Test invalid IR (missing required fields, invalid references). Test edge cases (empty nodes array, self-referential edges)."
          },
          {
            "id": 2,
            "title": "Implement Validation Functions and Error Handling",
            "description": "Add validation functions that use the jsonschema library to validate IR against the schema. Implement robust JSON loading with graceful error handling. Create custom validation error messages that provide clear guidance for fixing issues.",
            "dependencies": [
              1
            ],
            "details": "Add jsonschema to project dependencies if not present. Implement validate_ir() function using jsonschema. Create custom ValidationError with helpful error messages. Add JSON loading function with proper error handling. Include path to invalid field in error messages. Suggest fixes for common mistakes. Write comprehensive validation tests.",
            "status": "done",
            "testStrategy": "Test validation of all schema constraints. Test clear error messages for various failure modes. Test JSON loading with malformed files. Test helpful error suggestions."
          },
          {
            "id": 3,
            "title": "Create Examples and Documentation",
            "description": "Develop comprehensive valid and invalid IR examples for testing and documentation. Add detailed docstrings to all functions. Create example workflows that demonstrate all features of the IR schema including template variables, mappings, and action-based routing.",
            "dependencies": [
              2
            ],
            "details": "Create multiple valid IR examples (simple to complex). Create invalid IR examples for each validation rule. Add comprehensive module and function docstrings. Include examples in docstrings. Document template variable support ($variable syntax). Create examples showing mappings usage. Polish error messages based on example testing.",
            "status": "done",
            "testStrategy": "All examples must be tested programmatically. Valid examples must pass validation. Invalid examples must fail with expected errors. Documentation examples must be executable."
          }
        ]
      },
      {
        "id": 7,
        "title": "Extract node metadata from docstrings",
        "description": "Parse node docstrings to understand inputs, outputs, and parameters",
        "status": "done",
        "dependencies": [
          5
        ],
        "priority": "medium",
        "details": "Create src/pflow/registry/metadata_extractor.py with extract_metadata(node_class) function. IMPORTANT: Takes a node CLASS as input (not registry data). Since Task 5 only stores metadata, this function will be called by components that have already imported the class (e.g., Task 4 after dynamic import, or during testing). Parse the class's __doc__ to extract: 1) Description (first paragraph), 2) Interface section parsing (Reads/Writes/Params/Actions), 3) Classification of parameters (shared store vs node.set_params). Verify the class inherits from pocketflow.BaseNode. Use regex patterns to parse the simple bullet list format used in pflow docstrings (- Reads:, - Writes:, - Params:, - Actions:). Output format: {'description': 'Get GitHub issue', 'inputs': ['issue_number', 'repo'], 'outputs': ['issue'], 'params': ['token'], 'actions': ['default', 'not_found']}. This parsed metadata is used by the planner for intelligent node selection and connection. Do NOT duplicate Task 5's work - only parse docstrings. Reference: metadata-extraction.md, simple-nodes.md#interface-pattern",
        "testStrategy": "Test extraction from various docstring formats focusing on the simple bullet list format (- Reads:, - Writes:, - Params:, - Actions:), verify correct parsing of Interface sections using regex patterns, test parameter classification (shared vs params), verify BaseNode inheritance check, handle edge cases (missing sections, malformed docstrings, no Interface section). Create test nodes that inherit from BaseNode for testing. Ensure extractor is resilient to docstring variations while extracting accurate metadata.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Core Metadata Extractor with Node Validation",
            "description": "Create the foundational metadata extractor class with basic docstring parsing functionality. Implement the main extract_metadata() method that validates node inheritance from pocketflow.BaseNode and extracts the description from docstrings.",
            "dependencies": [],
            "details": "Create src/pflow/registry/metadata_extractor.py with PflowMetadataExtractor class. Implement extract_metadata(node_class) that: 1) Validates the class inherits from pocketflow.BaseNode (or Node which inherits from BaseNode), 2) Extracts the first paragraph of the docstring as description, 3) Returns the specified output format {'description': str, 'inputs': [], 'outputs': [], 'params': [], 'actions': []} with empty lists for unparsed sections. Include proper error handling for missing docstrings and non-node classes.",
            "status": "done",
            "testStrategy": "Create tests/test_registry/test_metadata_extractor.py with tests for: node inheritance validation (both Node and BaseNode), description extraction from various docstring formats, handling of missing docstrings, rejection of non-node classes"
          },
          {
            "id": 2,
            "title": "Implement Interface Section Parsing with Regex Patterns",
            "description": "Add regex-based parsing for the Interface section of docstrings. Parse the bullet-list format used in actual pflow nodes to extract Reads, Writes, Params, and Actions from the standardized docstring format.",
            "dependencies": [
              1
            ],
            "details": "Extend the extractor to parse Interface sections using regex patterns. Implement parsing for: '- Reads:' lines to extract shared store keys (e.g., shared['key']), '- Writes:' lines for output keys, '- Params:' lines for node parameters (distinguish required/optional), '- Actions:' lines for action names. Handle multi-line continuations and gracefully handle missing or partial Interface sections. Use patterns like r'- Reads:\\s*(.+)' and extract keys from shared['key'] syntax.",
            "status": "done",
            "testStrategy": "Test with actual node docstrings from /src/pflow/nodes/file/*.py, verify extraction of shared['key'] patterns, test parameter parsing with optional/required markers, test action parsing with descriptions, test partial Interface sections"
          },
          {
            "id": 3,
            "title": "Add Comprehensive Tests and Edge Case Handling",
            "description": "Create a comprehensive test suite covering all edge cases and ensure the extractor works with all existing pflow nodes. Polish error messages and add structured logging for debugging.",
            "dependencies": [
              2
            ],
            "details": "Complete the test suite in tests/test_registry/test_metadata_extractor.py. Test all file nodes (read_file, write_file, copy_file, move_file, delete_file) and test nodes. Add structured logging with phase tracking ('docstring_parse', 'field_extraction', 'validation'). Implement graceful fallbacks for malformed docstrings, non-English characters, and extremely long docstrings. Ensure exact output format compliance and add performance considerations.",
            "status": "done",
            "testStrategy": "Achieve 100% test coverage of metadata extractor, test malformed docstrings and recovery, test non-English characters, verify all existing nodes can be parsed successfully, ensure error messages are clear and actionable"
          }
        ]
      },
      {
        "id": 8,
        "title": "Build comprehensive shell pipe integration",
        "description": "Implement dual-mode Unix pipe support for stdin handling (workflow definitions OR data) and shell integration, building on existing stdin detection infrastructure",
        "status": "done",
        "dependencies": [
          3
        ],
        "priority": "high",
        "details": "Enhance existing CLI infrastructure to support dual-mode stdin handling where stdin can contain either workflow definitions OR data for workflows. Key implementation points: 1) Modify CLI validation at lines 52-55 in main.py to allow stdin + args combination, 2) Inject stdin data into shared storage at line 89 when detected as data (not workflow), 3) Implement smart detection to distinguish between workflow JSON and data input, 4) Use temporary files for large inputs (>10MB), 5) Auto-detect binary/text content, 6) Make output key configurable (default: 'stdin'), 7) Default to batch mode (fail fast) with optional interactive mode. The stdin detection logic already exists - focus on extending it for dual-mode support. Reference critical handover document for user decisions and implementation approach. Enable both: 'cat data.txt | pflow run workflow.json' AND 'echo {workflow} | pflow run'. Reference docs: shell-pipes.md, architecture.md#5.1.1",
        "testStrategy": "Create comprehensive test suite in tests/test_shell_integration.py with both unit tests (using pytest fixtures and mocks for sys.stdin) AND integration tests (using subprocess for real shell behavior). Test cases: 1) Dual-mode detection - distinguish workflow JSON from data input, 2) CLI validation bypass for stdin+args combination, 3) Shared storage injection verification at the correct point, 4) Large data handling with temporary files (test >10MB threshold), 5) Binary vs text auto-detection, 6) Configurable output key functionality, 7) Exit code propagation for both success and error cases, 8) Signal handling (Ctrl+C), 9) Integration with real Unix tools (echo, cat, grep) using subprocess. Ensure tests cover the modified validation logic and shared storage injection points.",
        "subtasks": [
          {
            "id": 1,
            "title": "Create shell_integration.py with dual-mode stdin handling",
            "description": "Build the foundational shell integration module that provides core utilities for stdin detection, reading, and mode determination",
            "dependencies": [],
            "details": "Create src/pflow/core/shell_integration.py with: detect_stdin() using not sys.stdin.isatty(), read_stdin() with UTF-8 encoding and error handling, determine_stdin_mode(content) that checks for 'ir_version' to detect workflow JSON vs data, populate_shared_store(shared, content) to add stdin data to shared['stdin']. Handle empty stdin by returning None. Include proper type hints and docstrings.",
            "status": "done",
            "testStrategy": "Unit tests for all functions using pytest, mock stdin with io.StringIO and monkeypatch, test edge cases: empty stdin, very large inputs, encoding errors, binary data detection"
          },
          {
            "id": 2,
            "title": "Update CLI to allow stdin data with file/args workflows",
            "description": "Modify the existing CLI validation logic to enable dual-mode stdin behavior where stdin can be data while workflow comes from file or args",
            "dependencies": [
              1
            ],
            "details": "Modify get_input_source() in src/pflow/cli/main.py at lines 52-55. Update validation to allow stdin when --file is provided. Implement logic: if --file provided, stdin is data; if no --file, stdin could be workflow. Store stdin data in click context (ctx.obj) for later injection. Preserve backward compatibility for echo '{workflow}' | pflow pattern.",
            "status": "done",
            "testStrategy": "Test both modes with CliRunner: stdin as workflow, stdin as data with --file. Verify validation logic changes work correctly. Ensure backward compatibility with existing usage patterns."
          },
          {
            "id": 3,
            "title": "Inject stdin data into shared storage before workflow execution",
            "description": "Integrate stdin data population at the correct point in the workflow execution pipeline",
            "dependencies": [
              1,
              2
            ],
            "details": "Modify workflow execution around line 89 in main.py. Import shell_integration module. If stdin data exists in context and is determined to be data (not workflow), call populate_shared_store(shared_storage, stdin_data) BEFORE flow.run(shared_storage). Add debug logging when stdin is populated into shared store.",
            "status": "done",
            "testStrategy": "Integration tests verifying stdin appears in shared store with correct key. Test with real workflows that access shared['stdin']. Verify injection happens before workflow execution."
          },
          {
            "id": 4,
            "title": "Implement binary detection and streaming for large inputs",
            "description": "Enhance stdin handling to support binary data and efficiently handle large files using temporary files",
            "dependencies": [
              1
            ],
            "details": "Add detect_binary_content(sample) using heuristics (check for null bytes). Implement read_stdin_with_limit(max_size=10_000_000). For inputs >10MB, write to temp file using tempfile.NamedTemporaryFile and store path in shared['stdin_path']. For binary content, use sys.stdin.buffer and store in shared['stdin_binary'] as bytes. Implement cleanup mechanism for temporary files.",
            "status": "done",
            "testStrategy": "Test binary detection with various file types. Test large file handling with >10MB inputs. Verify temporary file creation and cleanup. Test memory efficiency with streaming."
          },
          {
            "id": 5,
            "title": "Add configurable stdout output from shared store and Implement proper signal handling and exit codes",
            "description": "Enable workflows to output results to stdout for Unix pipe chaining and Add Unix-compliant signal handling and exit code propagation for shell script compatibility",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Add --output-key option to CLI with default auto-detection. Implement smart key detection checking for 'response', 'output', 'result', 'text' in order. Create safe_output(text) handling encoding errors and broken pipes. After workflow execution, check if stdout is piped (not TTY) and output selected key's value. Handle binary output from shared store appropriately. Also Create ExitCodes enum with standard codes (0=success, 1=error, 2=misuse, 130=SIGINT). Enhance existing SIGINT handler to exit with code 130. Add SIGPIPE handler using signal.signal(signal.SIGPIPE, signal.SIG_DFL) with hasattr check for Windows. Handle BrokenPipeError by exiting cleanly with os._exit(0). Propagate exit codes from workflow execution results.",
            "status": "done",
            "testStrategy": "Test output key selection logic, pipe chaining with subprocess (echo 'data' | pflow run workflow.json | grep pattern). Test encoding safety and binary output handling. Test signal handling with subprocess sending SIGINT. Test broken pipe scenarios (pflow run | head -n1). Verify correct exit codes for various error conditions. Platform-specific tests for Windows vs Unix."
          },
          {
            "id": 6,
            "title": "Build complete test coverage for shell integration",
            "description": "Create thorough test suite covering all shell integration features with both unit and integration tests",
            "dependencies": [
              1,
              2,
              3,
              4,
              5,
              6
            ],
            "details": "Create tests/test_shell_integration.py with comprehensive coverage. Unit tests using pytest fixtures and mocks. Integration tests using subprocess for real shell behavior. Test dual-mode detection, large files, binary data, signals, exit codes. Test real Unix command scenarios. Platform-specific tests for differences. Performance tests for large data. Aim for >95% coverage of shell_integration module.",
            "status": "done",
            "testStrategy": "Organize tests by feature area. Use parameterized tests for multiple scenarios. Mock external dependencies. Use subprocess for end-to-end tests. Include stress tests for large inputs and edge cases."
          }
        ]
      },
      {
        "id": 9,
        "title": "Implement shared store collision detection and proxy mapping",
        "description": "Create validation for collision detection and NodeAwareSharedStore proxy for transparent key mapping",
        "status": "pending",
        "dependencies": [
          3,
          7
        ],
        "priority": "medium",
        "details": "Merge validation and proxy implementation into src/pflow/core/proxy.py. Implement: 1) get_reserved_keys() returning ['stdin'], 2) detect_collisions(node_interfaces) to find key conflicts between nodes in a flow, 3) NodeAwareSharedStore class for transparent mapping around collisions and reserved keys. The proxy uses collision detection internally to know what needs mapping. Zero overhead when no collisions exist. Support input_mappings and output_mappings. Fail fast on missing required inputs. Include basic key existence validation: when a node requires an input key, verify it exists in the shared store before execution. This prevents silent failures and provides clear error messages. This minimal validation is essential for the proxy pattern to function correctly in MVP. Note: Natural pattern validation is NOT needed - nodes define their own conventions. Only validate for reserved keys and collisions. Reference docs: shared-store.md#2, cli-runtime.md#3",
        "testStrategy": "Test collision detection with various node combinations, proxy mapping scenarios, reserved key handling, and performance overhead. Verify fail-fast behavior and zero-overhead direct access. Test key existence validation to ensure missing keys produce clear error messages before node execution.",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Create registry CLI commands",
        "description": "Implement CLI commands for registry operations: list, describe, and search nodes",
        "status": "pending",
        "dependencies": [
          2,
          5,
          7
        ],
        "priority": "medium",
        "details": "Create src/pflow/cli/registry.py. Implement 'pflow registry list' showing individual platform nodes, 'pflow registry describe <node>' for detailed info with rich formatting for node-specific parameters. Part of enhanced registry infrastructure for fast lookups by node ID and capabilities. Reference docs: registry.md",
        "testStrategy": "Test CLI output formatting, search functionality, and error handling. Write integration tests for registry commands."
      },
      {
        "id": 11,
        "title": "Implement read-file and write-file nodes",
        "description": "Create basic file I/O nodes for reading and writing files",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "details": "Create file nodes in src/pflow/nodes/file/, all inheriting from pocketflow.BaseNode: read_file.py, write_file.py, copy_file.py, move_file.py, and delete_file.py. Each node should have explicit name attribute (e.g., class ReadFileNode(BaseNode): name = 'read-file') or rely on kebab-case conversion from class name. Simple interfaces: read-file uses shared['file_path'] \u2192 shared['content'], write-file uses shared['content'] + shared['file_path'], copy/move use shared['source_path'] + shared['dest_path'], delete uses shared['file_path']. Include safety checks for all destructive operations. Fail fast on missing required inputs. Natural interface pattern for file operations. Reference docs: simple-nodes.md",
        "testStrategy": "Test file operations, permission handling, and safety validations. Test fail-fast behavior. Write comprehensive unit tests.",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement foundational read-file and write-file nodes",
            "description": "Create the core file I/O nodes (read-file and write-file) in src/pflow/nodes/file/, establishing the patterns and conventions that will be used by all file nodes. These foundational nodes will handle the most common file operations and set the standard for error handling and interface design.",
            "dependencies": [],
            "details": "Create src/pflow/nodes/file/ directory structure. Implement read_file.py with ReadFileNode class inheriting from pocketflow.Node, using shared['file_path'] as input and writing to shared['content']. Support encoding parameter (default UTF-8), add line numbers when displaying content, and handle missing files gracefully. Implement write_file.py with WriteFileNode class, reading from shared['content'] and shared['file_path'], creating directories automatically with os.makedirs(exist_ok=True), supporting append mode via params, and validating content before writing. Follow node lifecycle: prep (validate inputs) \u2192 exec (file operation) \u2192 post (update shared store). Use error handling pattern returning tuples (result, success) from exec. Create __init__.py to expose nodes for registry discovery.",
            "status": "done",
            "testStrategy": "Test successful read/write operations, missing file handling for read, directory creation for write, various encodings, empty files, fail-fast behavior on missing inputs, and integration with shared store. Write tests alongside implementation using pytest."
          },
          {
            "id": 2,
            "title": "Implement file manipulation nodes (copy, move, delete)",
            "description": "Build on the foundation from subtask 1 to implement the remaining file manipulation nodes (copy-file, move-file, delete-file), following established patterns and adding appropriate safety checks for destructive operations.",
            "dependencies": [
              1
            ],
            "details": "Implement copy_file.py with CopyFileNode class using shared['source_path'] and shared['dest_path'], verifying source exists before operation, creating destination directory if needed, and preserving file attributes using shutil. Implement move_file.py with MoveFileNode class using same interface as copy, preferring atomic operation when possible (os.rename), with fallback to copy+delete for cross-filesystem moves, and adding safety check for overwriting existing files. Implement delete_file.py with DeleteFileNode class using shared['file_path'] input, adding safety parameter to prevent accidental deletions, providing clear error messages for missing files, and logging destructive operations. All nodes follow the same lifecycle pattern established in subtask 1 with consistent error handling and shared store conventions.",
            "status": "done",
            "testStrategy": "Test successful copy/move/delete operations, safety checks and confirmations, cross-filesystem operations, permission errors, operations on non-existent files, preservation of file attributes, and atomic vs non-atomic move operations. Include integration tests demonstrating node interaction."
          },
          {
            "id": 3,
            "title": "Polish with comprehensive error handling and edge cases",
            "description": "Enhance all file nodes with robust error handling, comprehensive edge case coverage, and polished user experience. Add any missing tests and ensure all nodes handle permission errors, special characters, and large files gracefully.",
            "dependencies": [
              2
            ],
            "details": "Add comprehensive error handling across all nodes: permission denied errors with helpful messages, disk space errors, invalid path characters, symbolic link handling, and network drive considerations. Enhance logging with structured metadata using phase tracking (reading, writing, validating), including file sizes and paths, avoiding reserved field names. Add performance considerations for handling large files efficiently, progress indicators for long operations, and reasonable timeouts. Polish user experience with clear, actionable error messages, consistent action returns ('default' for success, 'error' for failures), and helpful docstrings with examples. Create integration tests demonstrating node chaining and document all nodes in module docstrings.",
            "status": "done",
            "testStrategy": "Test permission error scenarios, special characters in filenames, symbolic links, large file handling, timeout scenarios, and full workflow integration. Ensure comprehensive test coverage across all edge cases and error conditions. Verify nodes are discoverable by registry scanner."
          }
        ]
      },
      {
        "id": 12,
        "title": "Implement general LLM node",
        "description": "Create the general-purpose LLM node for all text processing tasks",
        "status": "pending",
        "dependencies": [
          9
        ],
        "priority": "medium",
        "details": "Create src/pflow/nodes/llm.py inheriting from pocketflow.BaseNode. Set explicit name attribute: class LLMNode(BaseNode): name = 'llm'. Simple interface for general text processing. Natural interface: shared['prompt'] \u2192 shared['response']. Support multiple providers (Claude API, OpenAI). Fail fast on missing prompt with clear error message asking user for input. Smart exception to prevent prompt node proliferation. Reference docs: core-node-packages/llm-nodes.md, architecture.md#3.4",
        "testStrategy": "Mock LLM API responses, test different providers and parameter configurations. Test retry logic and error handling."
      },
      {
        "id": 13,
        "title": "Implement core platform nodes (GitHub, Git, CI, Shell)",
        "description": "Create all MVP platform nodes for GitHub, Git, CI, and Shell operations",
        "status": "pending",
        "dependencies": [
          9
        ],
        "priority": "medium",
        "details": "Create all MVP platform nodes inheriting from pocketflow.BaseNode:\n\nGITHUB NODES (src/pflow/nodes/github/):\n- github_get_issue.py: shared['repo'], shared['issue_number'] \u2192 shared['issue_data'], shared['issue_title']\n- github_create_pr.py: shared['pr_title'], shared['pr_body'], shared['repo'] \u2192 shared['pr_number']\n- github_list_prs.py: shared['repo'], shared['state'] \u2192 shared['prs']\n- github_add_comment.py: shared['pr_number'], shared['comment'] \u2192 shared['comment_id']\n- github_merge_pr.py: shared['pr_number'], shared['merge_method'] \u2192 shared['merge_sha'] (with conflict handling)\n\nGIT NODES (src/pflow/nodes/git/):\n- git_commit.py: shared['message'], shared['files'] \u2192 shared['commit_hash']\n- git_push.py: shared['branch'] \u2192 shared['push_result']\n- git_create_branch.py: shared['branch_name'] \u2192 shared['branch_created']\n- git_merge.py: shared['source_branch'], shared['target_branch'] \u2192 shared['merge_result']\n- git_status.py: \u2192 shared['git_status']\n\nCI NODES (src/pflow/nodes/ci/):\n- ci_run_tests.py: shared['test_command'] \u2192 shared['test_results']\n- ci_get_status.py: shared['build_id'] \u2192 shared['build_status']\n- ci_trigger_build.py: shared['build_config'] \u2192 shared['build_id']\n- ci_get_logs.py: shared['build_id'] \u2192 shared['build_logs']\n\nSHELL NODES (src/pflow/nodes/shell/):\n- shell_exec.py: shared['command'] \u2192 shared['output'], shared['exit_code']\n- shell_pipe.py: shared['commands'] \u2192 shared['output']\n- shell_background.py: shared['command'] \u2192 shared['pid']\n\nAll nodes use:\n- Natural interfaces with intuitive shared store keys\n- Explicit name attributes (e.g., class GitHubGetIssueNode(BaseNode): name = 'github-get-issue')\n- Proper error handling with clear messages\n- Authentication via environment variables (GITHUB_TOKEN, etc.)\n- Safety checks for destructive operations\n- Fail fast on missing required inputs\n- Support for multiple CI systems (GitHub Actions, Jenkins, local)\n- Timeout handling for long-running operations\n\nReference docs: simple-nodes.md",
        "testStrategy": "Mock all external API responses and system commands. Test parameter handling, error cases, safety measures, and timeouts. Write comprehensive unit tests for each node. Test fail-fast behavior on missing inputs."
      },
      {
        "id": 16,
        "title": "Create planning context builder",
        "description": "Format node metadata for LLM-based workflow planning",
        "status": "done",
        "dependencies": [
          7
        ],
        "priority": "critical",
        "details": "Create src/pflow/planning/context_builder.py with build_context(registry_metadata) function. Format node information into a structured text that LLMs can understand: node names, descriptions, inputs/outputs, parameter types. Keep format simple and readable - just markdown tables or structured text. Include which parameters go to shared store vs node.set_params(). This provides the LLM with available 'tools' for building workflows. Output example: 'Available nodes:\n- read-file: Reads file from disk\n  Inputs: file_path (from shared store)\n  Outputs: content (to shared store)'. Reference docs: planner.md#6.1",
        "testStrategy": "Test context generation, metadata optimization, and LLM readability. Verify output format is parseable.",
        "subtasks": [
          {
            "id": 1,
            "title": "Create core context builder with basic formatting",
            "description": "Create the initial src/pflow/planning/context_builder.py module with the build_context() function. Implement basic node formatting that transforms metadata into markdown text. Focus on the core transformation logic without worrying about categories or optimization.",
            "dependencies": [],
            "details": "Create the planning directory and context_builder.py file. Implement build_context(registry_metadata: dict[str, dict[str, Any]]) -> str. Format individual nodes into markdown sections. Apply the 'exclusive parameters' pattern - filter out params that are also inputs. Use simple, consistent formatting for each node.",
            "status": "done",
            "testStrategy": "Test basic formatting with sample metadata. Test parameter filtering (exclusive params only). Test output format consistency. Test with minimal metadata (just description)."
          },
          {
            "id": 2,
            "title": "Integrate registry loading and metadata extraction",
            "description": "Integrate the context builder with Task 5's registry and Task 7's metadata extractor. Add dynamic node class importing, handle import failures gracefully, and implement the production node filtering logic.",
            "dependencies": [
              1
            ],
            "details": "Import and use PflowMetadataExtractor from Task 7. Use import_node_class() from runtime.compiler for dynamic imports. Handle import failures with logging (skip failed nodes). Filter to include only production nodes with valid Interface sections. Skip nodes without metadata entirely. Add structured logging with phase tracking.",
            "status": "done",
            "testStrategy": "Test integration with real registry data. Test import failure handling. Test filtering of test nodes vs production nodes. Test with nodes that have no Interface section. Verify logging for skipped nodes."
          },
          {
            "id": 3,
            "title": "Add category organization and format optimization",
            "description": "Enhance the output format by organizing nodes into logical categories (File Operations, Git Operations, etc.). Optimize the markdown format for LLM comprehension and add monitoring for context size.",
            "dependencies": [
              2
            ],
            "details": "Implement category detection based on node paths/names. Group nodes by category in the output. Add section headers for better organization. Implement size monitoring (log warnings for large contexts). Polish the markdown format based on planner.md examples. Ensure clear distinction between shared store and configuration params.",
            "status": "done",
            "testStrategy": "Test category grouping logic. Test output format matches examples in documentation. Test size monitoring warnings. Integration test with multiple node types. Verify LLM-friendly formatting."
          }
        ]
      },
      {
        "id": 17,
        "title": "Implement Natural Language Planner System",
        "description": "Build the complete planner that transforms natural language into workflows, handles the 'find or build' pattern, and enables workflow reuse",
        "status": "pending",
        "dependencies": [
          16
        ],
        "priority": "critical",
        "details": "Create the complete planning system in src/pflow/planning/ that enables the core pflow value proposition: 'Plan Once, Run Forever' with natural language discovery.\n\nImplementation includes:\n\n1. WORKFLOW GENERATION ENGINE (src/pflow/planning/workflow_compiler.py)\n   - compile_request(user_input, node_context) function\n   - Receives entire raw input string from CLI\n   - Uses LLM to interpret as domain-specific language\n   - Recognizes node names and parameter conventions\n   - Generates workflows with template variables like $issue_data\n   - Fills in missing parameters intelligently\n   - Target \u226595% success rate for natural language \u2192 workflow\n\n2. PROMPT TEMPLATES (src/pflow/planning/prompts.py)\n   - Workflow generation prompt with node context and examples\n   - Error recovery prompt for failed attempts\n   - Template variable extraction prompt\n   - Use f-strings or jinja2 for composition\n   - Format: WORKFLOW_PROMPT = '''Given these nodes: {node_context}\\nGenerate a workflow for: {user_request}\\nOutput JSON IR...'''\n\n3. TEMPLATE RESOLUTION (src/pflow/planning/utils.py)\n   - resolve_template(template_str, available_vars) function\n   - Simple regex-based string substitution\n   - Validates template variables can be resolved at runtime\n   - NOT a runtime templating engine - planner internal use only\n   - Support $var and ${var} syntax, escaping with $$var\n\n4. WORKFLOW DISCOVERY (src/pflow/planning/discovery.py) [NEW]\n   - find_similar_workflows(user_input, saved_workflows) function\n   - Uses LLM embeddings or similarity matching\n   - Finds workflows by semantic meaning, not just name\n   - Enables \"pflow 'analyze costs'\" to find 'aws-cost-analyzer'\n   - Returns ranked list of potential matches\n   - Critical for \"find or build\" user experience\n\n5. APPROVAL AND STORAGE (src/pflow/planning/approval.py, src/pflow/core/workflow_storage.py)\n   - Show generated CLI workflow for user approval\n   - Clear presentation of individual node syntax\n   - Allow parameter modifications before execution\n   - Save to ~/.pflow/workflows/<name>.json\n   - Implement name-based retrieval and pattern matching\n   - Support loading workflows by name for execution\n   - Target \u226590% user approval rate\n\nThis is the core feature that makes pflow unique. References: docs/planner.md#6.1, workflow-analysis.md",
        "testStrategy": "Test workflow generation accuracy for natural language inputs. Verify LLM correctly interprets CLI-like syntax. Test template variable generation and validation. Test workflow discovery by semantic similarity. Test approval flow and storage. Verify \u226595% success rate for NL\u2192workflow generation."
      },
      {
        "id": 21,
        "title": "Implement workflow lockfile system",
        "description": "Create lockfile generation for deterministic workflow execution",
        "status": "deferred",
        "dependencies": [
          17
        ],
        "priority": "medium",
        "details": "Create src/pflow/core/lockfile.py to generate and manage workflow lockfiles. After workflow validation, generate lockfile containing: workflow IR hash, node versions from registry, execution timestamp, pflow version. Store lockfiles alongside workflows in ~/.pflow/workflows/<name>.lock. Lockfiles ensure deterministic execution across environments and time. Include functions: generate_lockfile(workflow, registry), validate_lockfile(lockfile, registry), check_compatibility(lockfile). This is critical for 'Plan Once, Run Forever' - workflows must execute identically months later. Reference docs: PRD#5.6, architecture.md",
        "testStrategy": "Test lockfile generation, validation, version compatibility checks. Test deterministic execution with lockfiles."
      },
      {
        "id": 22,
        "title": "Implement named workflow execution",
        "description": "Enable execution of saved workflows by name with parameters",
        "status": "pending",
        "dependencies": [
          17,
          21
        ],
        "priority": "high",
        "details": "Extend CLI to support executing saved workflows by name: 'pflow fix-issue --issue=1234'. Create src/pflow/cli/execute.py with execute_named_workflow(name, params) function. Load workflow from ~/.pflow/workflows/<name>.json, validate against lockfile, apply runtime parameters to template variables, execute via IR compiler. This is the core user-facing command that delivers the 'Plan Once, Run Forever' value. Support parameter override and validation. Include helpful error messages for missing workflows or parameters. Reference docs: mvp-scope.md, cli-reference.md",
        "testStrategy": "Test workflow loading, parameter application, execution flow. Test error cases and parameter validation."
      },
      {
        "id": 23,
        "title": "Implement execution tracing system",
        "description": "Build comprehensive execution visibility for debugging and optimization",
        "status": "pending",
        "dependencies": [
          3
        ],
        "priority": "high",
        "details": "Create src/pflow/runtime/tracing.py with execution tracing that helps users understand, debug, and optimize execution flow. Capture and display: inputs/outputs for each node, shared state diffs per step, LLM tokens used per node and total, execution time per node, cache hits/misses. Format output clearly with proper error context: '[1] read-file (0.02s) Input: {file_path: 'data.txt'} Output: {content: '...'} Shared Store \u0394: +content'. Support different verbosity levels via --trace flag. Include cost estimation for LLM nodes ($0.0012 per call). Persist execution traces to ~/.pflow/traces/<run-id>.json for post-execution analysis. Implement 'pflow trace <run-id>' command to retrieve and display saved traces. Critical for understanding workflow behavior and optimizing performance. Reference docs: architecture.md (observability), runtime.md",
        "testStrategy": "Test trace output formatting, performance overhead, and debugging effectiveness. Verify error context is clear."
      },
      {
        "id": 24,
        "title": "Build caching system",
        "description": "Implement node-level caching for flow_safe nodes",
        "status": "pending",
        "dependencies": [
          3
        ],
        "priority": "medium",
        "details": "Create src/pflow/runtime/cache.py as optional performance optimization. Simple disk-based cache using pickle or json. Cache key = hash(node_type + params + inputs). Store in ~/.pflow/cache/. Only cache nodes marked as @flow_safe (deterministic). Start with just LLM nodes to save API costs. Can be disabled via --no-cache flag. This is not critical for MVP - implement only if performance becomes an issue. Reference docs: runtime.md#caching-strategy",
        "testStrategy": "Test cache hits/misses, key computation, and storage operations. Test cache invalidation."
      },
      {
        "id": 25,
        "title": "Implement claude-code super node",
        "description": "Create the comprehensive Claude Code node for AI-assisted development with project context",
        "status": "pending",
        "dependencies": [
          9
        ],
        "priority": "high",
        "details": "Create src/pflow/nodes/claude_code.py inheriting from pocketflow.BaseNode. Set explicit name attribute: class ClaudeCodeNode(BaseNode): name = 'claude-code'. Single powerful node with instruction-based interface for AI-assisted development with full project context and file system access. Complex prompt generation from planner templates with structured instructions. Integration with headless Claude Code CLI for workflow automation. Natural interface: shared['prompt'] \u2192 shared['code_report'] (comprehensive development report). Model selection and parameter handling. Fail fast on missing required inputs (prompt) with clear error message. Part of two-tier AI approach. Reference docs: core-node-packages/claude-nodes.md",
        "testStrategy": "Mock Claude Code CLI responses, test template processing and output parsing. Test error handling and timeout scenarios."
      },
      {
        "id": 29,
        "title": "Create comprehensive test suite",
        "description": "Build integration tests for all components not covered by unit tests",
        "status": "pending",
        "dependencies": [
          2,
          8,
          9,
          10,
          11,
          12,
          13,
          17,
          21,
          22,
          4,
          5,
          6,
          7,
          23,
          24
        ],
        "priority": "high",
        "details": "Create tests/ structure for integration and performance tests (unit tests already created with each task). Integration tests for end-to-end workflows. Performance benchmark suite in tests/benchmarks/ measuring planning latency (\u2264800ms target), execution speed (\u22642s overhead target), token usage optimization. Error recovery test suite in tests/error_recovery/ for invalid input handling, external service failures, partial execution scenarios. Mock external services. Test natural language \u2192 workflow generation with \u226595% success rate target.",
        "testStrategy": "Achieve >90% code coverage including integration scenarios. Test all critical paths and error scenarios."
      },
      {
        "id": 30,
        "title": "Polish CLI experience and documentation",
        "description": "Enhance user experience with better error messages, help text, and initial documentation",
        "status": "pending",
        "dependencies": [
          29
        ],
        "priority": "low",
        "details": "Improve error messages with actionable suggestions and clear next steps. Add comprehensive --help for all commands. Create initial README with quickstart guide showing primary workflow example (GitHub issue resolution). Update relevant documentation as features are implemented. Support developer workflow scenarios including slash command comparison (10x efficiency gain target). Reference docs: architecture.md#11.3",
        "testStrategy": "User acceptance testing, documentation review, error message clarity testing."
      },
      {
        "id": 31,
        "title": "Create MVP validation test suite",
        "description": "End-to-end validation that MVP meets all acceptance criteria",
        "status": "pending",
        "dependencies": [
          29
        ],
        "priority": "high",
        "details": "Create tests/mvp_validation/ with end-to-end scenarios proving real value. Test core workflow: 'pflow \"fix github issue 123\"' generates appropriate workflow, executes successfully, creates PR with fix. Measure against MVP criteria: 10x faster than manual LLM interaction, natural language to workflow works, template resolution functions correctly, all platform nodes integrate properly. Include performance benchmarks showing planning \u2264800ms, execution overhead \u22642s. Document which v2.0 features are intentionally excluded. This is about proving the MVP delivers its core value proposition. Reference docs: mvp-scope.md, architecture.md#11",
        "testStrategy": "Test real-world scenarios, measure performance targets, validate user experience metrics."
      },
      {
        "id": 32,
        "title": "v2.0 Deferred Features",
        "description": "Features intentionally excluded from MVP that will be implemented in v2.0",
        "status": "deferred",
        "dependencies": [],
        "priority": "low",
        "details": "The following features are deferred to v2.0 to keep MVP focused:\n\n1. EXECUTION CONFIGURATION (was Task 32)\n   - Node-level retry configuration in runtime\n   - Support max_retries, retry_wait, timeout per node\n   - MVP uses simple hardcoded retry logic\n\n2. TRACE PERSISTENCE (was Task 44)\n   - Save execution traces to ~/.pflow/traces/<run-id>.json\n   - Implement 'pflow trace <run-id>' retrieval command\n   - MVP only needs real-time trace display\n\n3. NODE VERSION TRACKING (was Task 45)\n   - Track node versions for lockfile generation\n   - MVP uses git commit hash or hardcoded versions\n\n4. INTERFACE COMPATIBILITY SYSTEM (was Task 46)\n   - Advanced compatibility checking for marketplace\n   - MVP nodes have compatible interfaces by design\n\n5. SUCCESS METRICS (was Task 47)\n   - Comprehensive metrics tracking and instrumentation\n   - MVP uses basic logging\n\n6. DIRECT CLI PARSING (was Task 48)\n   - Parse CLI syntax without LLM for minor optimization\n   - MVP sends everything through LLM planner\n\n7. CLI AUTOCOMPLETE (was Task 49)\n   - Shell completion for node names and parameters\n   - Would provide significant UX improvement\n\n8. NESTED PROXY MAPPINGS (was Task 50)\n   - Support complex key mappings like 'data.content' -> 'file_data.text'\n   - MVP uses simple key-to-key mappings\n\n9. CONTEXT-AWARE CLI RESOLUTION (was Task 51)\n   - Smart flag validation and categorization\n   - MVP treats all input as natural language\n\nThese features will be revisited after MVP validation to ensure development focuses on core value proposition first.",
        "testStrategy": "N/A - Deferred to v2.0"
      }
    ],
    "metadata": {
      "created": "2025-06-18T20:41:12.050Z",
      "updated": "2025-07-10T21:36:34.759Z",
      "description": "Reorganized to prioritize Natural Language Planner as core feature. Merged tasks 17-20 into comprehensive planner system. Expanded task 13 to include all platform nodes. Consolidated all v2.0 deferred features into task 32. Clear path from infrastructure to MVP delivery."
    }
  }
}
