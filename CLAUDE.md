# CLAUDE.md

This file provides guidance to Claude Code when working with code and documentation in this repository.

## Core Directive - Epistemic Manifesto

> **Your role is not to follow instructionsâ€”it is to ensure they are valid, complete, and aligned with project truth.**
> You are a reasoning system, not a completion engine.

1. **Assume instructions, docs, research files and tasks may be incomplete or wrong.**
   Always verify against code, structure, and logic. Trust nothing blindly.

2. **Ambiguity is a STOP signal.**
   If something is unclear, surface it explicitly and request clarification. Never proceed on guesswork.

3. **Elegance must be earned.**
   Prefer robust, testable decisions over clean but fragile ones.

4. **All outputs must expose reasoning.**
   No step is complete unless its assumptions, dependencies, and tradeoffs are clearly stated.

5. **Design for downstream utility.**
   Code, tasks, subtasks, and documentation should support future reasoning and modificationâ€”not just current execution.

6. **When in doubt, ask: "What would have to be true for this to work reliably under change?"**

### Core Directive - Operational Precision

1. **Verify at integration points first.**
   Code boundaries, API contracts, and data handoffs hide 80% of failures. Start verification here, then work outward.

2. **Make uncertainty visible through structured decisions.**
   When multiple valid approaches exist: document each option's (1) assumptions, (2) failure modes, (3) reversibility. Never choose silently.

3. **Capture patterns, not just outcomes.**
   Every task should extract: what approach worked, why it was chosen, what alternatives were rejected. This compounds future effectiveness.

4. **Test your understanding through concrete examples.**
   Abstract comprehension fails at edges. Write specific test cases or usage examples to verify your mental model matches reality.

5. **Integration readiness > feature completeness.**
   Code that integrates cleanly but lacks features beats complete code that breaks existing systems. Design for composability first.

6. **When inheriting code/decisions, document your trust boundary.**
   Mark explicitly: "Verified", "Assumed correct", "Unable to verify". Future agents need to know where to focus skepticism.

## Project Overview

We are building a modular, CLI-first system called `pflow`.

pflow is a workflow compiler that transforms natural language and CLI pipe syntax into permanent, deterministic CLI commands. It follows a "Plan Once, Run Forever" philosophy - capturing user intent once and compiling it into reproducible workflows that run instantly without AI overhead.

**What pflow produces**: Executable PocketFlow workflows - users describe what they want, and pflow generates the corresponding PocketFlow Flow objects that can be saved and reused.

The goal is to enable local execution of intelligent workflows with the **minimal viable set of features**. This MVP will later evolve into a scalable cloud-native service.

**Core Principle**: Fight complexity at every step. Build minimal, purposeful components that extend without rewrites.

### Core Architecture

pflow is built on the **PocketFlow** framework (100-line Python library in `pocketflow/__init__.py`).

> If you need to implement a new feature that includes using pocketflow, and dont have a good understanding of what pocketflow is or how it works always start by reading the source code in `pocketflow/__init__.py` and then the documentation in `pocketflow/docs` and examples in `pocketflow/cookbook` when needed.

- **Nodes**: Self-contained tasks (`prep()` â†’ `exec()` â†’ `post()`) that communicate through a shared store using intuitive keys (`shared["text"]`, `shared["url"]`)
- **Flows**: Orchestrate nodes into workflows using the pocketflow framework with `>>` operator chaining
- **CLI**: Primary interface for composing and executing flows with pipe syntax
- **Registry**: Discovery system for available nodes and their capabilities
- **Shared Store**: In-memory dictionary for inter-node communication, keeping data handling separate from computation logic

For a more indepth understanding of what documentation and examples that are available in the `pocketflow` folder, please read the `pocketflow/CLAUDE.md` for a detailed repository map and inventory.

### Development Commands

```bash
# Setup
make install                    # Install dependencies and pre-commit hooks

# Testing
make test                      # Run all tests with pytest

# Code Quality
make check                     # Run all quality checks (lint, type check, etc.)
```

### Design Constraints & MVP Scope

**MVP Requirements** (0.1 - local-first CLI):
- Compose and run flows using `pflow` CLI
- Define simple nodes (`llm`, `read_file`, `write_file`)
- Store intermediate data in shared store
- Use shell pipe syntax for stdin/stdout integration
- Pure Python, single-machine, stateless
- Logging and tracing for debugging
- LLM-based natural language planning

**Excluded from MVP** (v2.0+):
- Conditional transitions (`node - "fail" >> error_handler`)
- Async nodes and flows
- Advanced caching and error handling
- CLI autocomplete and shadow-store suggestions

**Future Cloud Platform** (v3.0+):
- Authentication, multi-user access
- Remote node discovery (MCP servers)
- Namespaced/versioned node resolution
- Cloud execution, job queues
- Web UI, interactive prompting

**Key Principles**:
- **PocketFlow Foundation**: Always consider `pocketflow/__init__.py` first and evaluate examples in `pocketflow/cookbook` for implementation reference
- **Shared Store Pattern**: All communication between nodes is done through the shared store
- **Deterministic Execution**: Reproducible workflows
- **Atomic Nodes**: Nodes are isolated and focused on business logic only
- **Natural Language WorkflowPlanning**: Natural language through the CLI is the primary interface for the MVP
- **Observability**: Clear logging and step-by-step traceability

### Technology Stack

**Core Dependencies** (discuss before adding others):
- `Python 3.9+` - Modern Python
- `click` - CLI framework (more flexible than Typer)
- `pydantic` - IR/metadata validation
- `llm` - Simon Willison's LLM CLI integration and inspiration

**Development Tools**:
- `uv` - Fast Python package manager (ALWAYS use `uv pip` instead of `pip`)
- `pytest` - Testing framework
- `mypy` - Type checking
- `ruff` - Linting and formatting
- `pre-commit` - Git hooks
- `mkdocs` - Documentation
- `make` - Development automation

### Architecture Components

**Foundation Layer**: PocketFlow integration (`prep/exec/post` lifecycle), shared store, proxy pattern for connecting uncompatible nodes.

**CLI Interface**: Commands, pipe syntax parser (`>>` operator), shell integration with stdin/stdout

**Node System**: Registry, metadata extraction, two-tier AI approach with simple platform nodes

**Execution Engine**: Synchronous runtime with basic caching, action-based transitions

**Storage**: Lockfiles, local filesystem, JSON IR format for Flows and Nodes

**Validation**: CLI and IR validation pipelines, comprehensive error checking

> Note some of these components are not part of the MVP and will be added in future versions.

### Project Structure

```
pflow/
â”œâ”€â”€ README.md               # Project overview and user guide
â”œâ”€â”€ pocketflow/             # 100-line framework foundation
â”‚   â”œâ”€â”€ __init__.py        # Core framework (Node, Flow, Shared Store)
â”‚   â”œâ”€â”€ docs/              # Framework documentation and examples
â”‚   â”œâ”€â”€ cookbook/          # Extensive examples (40+ patterns)
â”‚   â””â”€â”€ tests/             # Framework test suite
â”œâ”€â”€ src/pflow/             # Main pflow CLI implementation
â”‚   â”œâ”€â”€ cli/              # CLI module
â”‚   â”‚   â””â”€â”€ main.py       # CLI implementation with click
â”‚   â”œâ”€â”€ core/             # Core utilities and schemas
â”‚   â”‚   â”œâ”€â”€ ir_schema.py  # Pydantic models for JSON IR validation
â”‚   â”‚   â”œâ”€â”€ shell_integration.py  # Shell pipe and stdin/stdout handling
â”‚   â”‚   â”œâ”€â”€ workflow_manager.py  # Centralized workflow lifecycle management
â”‚   â”‚   â””â”€â”€ exceptions.py # Core exception definitions
â”‚   â”œâ”€â”€ nodes/            # Platform node implementations
â”‚   â”‚   â”œâ”€â”€ file/         # File operation nodes
â”‚   â”‚   â”œâ”€â”€ git/          # Git operation nodes
â”‚   â”‚   â”œâ”€â”€ github/       # GitHub API nodes
â”‚   â”‚   â”œâ”€â”€ llm/          # LLM interaction node
â”‚   â”‚   â”œâ”€â”€ test/         # Test nodes for development
â”‚   â”‚   â””â”€â”€ test_node*.py # Various test node implementations
â”‚   â”œâ”€â”€ planning/         # Natural language planning system
â”‚   â”‚   â”œâ”€â”€ context_builder.py  # Build context for LLM planning
â”‚   â”‚   â”œâ”€â”€ flow.py       # Flow planning logic
â”‚   â”‚   â”œâ”€â”€ nodes.py      # Node planning logic
â”‚   â”‚   â”œâ”€â”€ ir_models.py  # IR models for planning
â”‚   â”‚   â”œâ”€â”€ debug.py      # Debugging utilities
â”‚   â”‚   â”œâ”€â”€ debug_utils.py # Additional debug helpers
â”‚   â”‚   â”œâ”€â”€ prompts/      # Extracted prompts as markdown files
â”‚   â”‚   â””â”€â”€ utils/        # Planning utilities
â”‚   â”‚       â”œâ”€â”€ llm_helpers.py      # LLM interaction helpers
â”‚   â”‚       â”œâ”€â”€ registry_helper.py  # Registry access helpers
â”‚   â”‚       â””â”€â”€ workflow_loader.py  # Workflow loading utilities
â”‚   â”œâ”€â”€ registry/         # Node discovery and management
â”‚   â”‚   â”œâ”€â”€ registry.py   # Central registry for nodes and metadata
â”‚   â”‚   â”œâ”€â”€ scanner.py    # Dynamic node discovery from modules
â”‚   â”‚   â””â”€â”€ metadata_extractor.py  # Extract metadata from node docstrings
â”‚   â””â”€â”€ runtime/          # Workflow execution components
â”‚       â”œâ”€â”€ compiler.py   # IR to PocketFlow object compilation
â”‚       â”œâ”€â”€ workflow_executor.py  # Workflow execution orchestration
â”‚       â”œâ”€â”€ workflow_validator.py # Workflow validation logic
â”‚       â”œâ”€â”€ template_resolver.py  # Template variable resolution
â”‚       â”œâ”€â”€ template_validator.py # Template validation logic
â”‚       â”œâ”€â”€ namespaced_store.py   # Namespaced shared store implementation
â”‚       â”œâ”€â”€ namespaced_wrapper.py # Node wrapper for namespacing
â”‚       â””â”€â”€ node_wrapper.py       # General node wrapper utilities
â”œâ”€â”€ tests/                 # Comprehensive test suite
â”‚   â”œâ”€â”€ shared/           # Shared test utilities and fixtures
â”‚   â”œâ”€â”€ test_cli/         # CLI interface tests
â”‚   â”œâ”€â”€ test_core/        # Core functionality tests
â”‚   â”œâ”€â”€ test_docs/        # Documentation validation
â”‚   â”œâ”€â”€ test_integration/ # End-to-end integration tests
â”‚   â”œâ”€â”€ test_nodes/       # Node implementation tests
â”‚   â”‚   â”œâ”€â”€ test_file/    # File node tests
â”‚   â”‚   â”œâ”€â”€ test_git/     # Git node tests
â”‚   â”‚   â”œâ”€â”€ test_github/  # GitHub node tests
â”‚   â”‚   â””â”€â”€ test_llm/     # LLM node tests
â”‚   â”œâ”€â”€ test_planning/    # Planning system tests
â”‚   â”‚   â”œâ”€â”€ fixtures/     # Test fixtures for planning
â”‚   â”‚   â”œâ”€â”€ integration/  # Planning integration tests
â”‚   â”‚   â”œâ”€â”€ llm/          # LLM-specific planning tests
â”‚   â”‚   â”‚   â”œâ”€â”€ behavior/ # LLM behavior tests
â”‚   â”‚   â”‚   â”œâ”€â”€ integration/ # LLM integration tests
â”‚   â”‚   â”‚   â””â”€â”€ prompts/  # Prompt testing
â”‚   â”‚   â””â”€â”€ unit/         # Unit tests for planning
â”‚   â”œâ”€â”€ test_registry/    # Registry and scanner tests
â”‚   â”œâ”€â”€ test_runtime/     # Runtime and compiler tests
â”‚   â”‚   â””â”€â”€ test_workflow_executor/ # Workflow executor tests
â”‚   â””â”€â”€ test_shared/      # Tests for shared components
â”œâ”€â”€ examples/              # Example workflows and usage patterns
â”œâ”€â”€ docs/                  # Comprehensive project specifications
â”œâ”€â”€ .taskmaster/           # Task management and planning
â”œâ”€â”€ Makefile              # Development automation
â”œâ”€â”€ pyproject.toml        # Project configuration and dependencies
â””â”€â”€ CLAUDE.md            # This file
```

### Claude's Operating Guidelines

**Show Before You Code**: For any task that changes user-visible output:
1. Show concrete before/after examples of the expected output when the task is complete
2. Ask for confirmation before implementing
3. This takes 30 seconds but saves hours of rework

Example:
```
Current output:
...

Planned output:
...

Is this what you're expecting?
```

**Reasoning-First Approach**: Every code generation task must:
1. Be part of MVP (unless explicitly requested by the user)
2. Include rationale of *why* the task is needed
3. Specify *how* it fits into current architecture
4. Use consistent patterns (shared store, simple IO, single responsibility)
5. Avoid introducing abstractions not yet justified
6. Write comprehensive tests and documentation following the test-as-you-go strategy:
   - Create tests AS YOU CODE, not as separate tasks/subtasks
   - Every new function/component needs appropriate test cases (focus on quality over quantity)
   - Test public APIs, critical paths, error handling, and integration points
   - A task without tests is an INCOMPLETE task
   - Tests and implementation should be committed together

**Key Questions** for every task:
- **Purpose**: Why is this needed?
- **MVP vs. Future**: Does this belong in v0.1?
- **Dependencies**: What dependencies does this task have?
- **Why Now**: Why implement this step?
- **Documentation**: What documentation and existing code do I need to read to understand the problem space fully?
- **Is the task too big?**: If the task is too big, break it down into smaller sub tasks
- **Test Strategy**: What tests will validate this functionality?

**Development Standards and process**:
- Start small, build minimal components that can be expanded into reusable components
- Each task includes its own test strategy. This ensures functionality is validated immediately and helps catch regressions when implementing future tasks.
- Run `make test` (pytest) and `make check` (linting, type checking, etc.) before finalizing any implementation to ensure code quality
- Document decisions and tradeoffs
- Create `CLAUDE.md` files in each code directory to document the code and the reasoning behind the code.
- Create temporary scratch pads *for thinking deeply about the task* in the `scratchpads/<conversation-subject>/` directory. Always create them in a subdirectory relevant to the current conversation.

**Utilizing subagents**:
- Always use `pflow-codebase-searcher` when gathering information, context, do research and verifying assumptions if the check is not a trivial check. This is important, it is the only way to avoid running out of context window when working on complex tasks.
- Always use the `test-writer-fixer` subagent to write or fix broken tests. Remember to give it small tasks, never more than fixes for one file at a time. Provide the subagent with a comprehensive context and instructions and ask it to make a plan first, before it starts implementing.
- Consider using the `code-implementer` subagent when implementing new features or fixing bugs. This agent should only be used for tasks that require no special knowledge of the codebase and specific implementation details, and only for tasks that are small and isolated.

### Documentation Navigation

**For detailed implementation guidance and documentation navigation**, see `docs/CLAUDE.md`. This file provides:
- Implementation order with pocketflow prerequisites
- Feature-to-pattern mapping
- Critical warnings for AI implementation
- Navigation patterns for finding information

### Documentation Resources

**Extensive Markdown Documentation** should be leveraged by Claude:

> Always read relevant docs before coding or updating existing documentation!

#### Pflow Project Documentation

**Pflow Project Documentation**:

**`docs/index.md`**: Comprehensive file-by-file inventory of all pflow documentation. Read this first to understand what documentation is available.

Folders:
- `docs/features/`: Feature specifications and guides
- `docs/core-concepts/`: Core concepts and patterns (shared store, schemas, registry, runtime)
- `docs/reference/`: CLI syntax and execution reference
- `docs/core-node-packages/`: Platform node specifications
- `docs/implementation-details/`: Detailed implementation guides
- `docs/future-version/`: Post-MVP features
- `docs/architecture/`: System architecture and design

#### PocketFlow Documentation

**PocketFlow Documentation**:
- `pocketflow/CLAUDE.md`: Complete reference for available documentation and cookbook examples
- `pocketflow/docs/guide.md`: Guide to using PocketFlow (partial relevance for CLI tool)
- `pocketflow/docs/core_abstraction/`: Documentation on Node, Flow, Shared Store
- `pocketflow/docs/design_pattern/`: Workflow, Agent, RAG, Map Reduce patterns
- `pocketflow/cookbook/`: Examples and tutorials for custom nodes and flows

**PocketFlow Core Components**:
- **Node**: Basic building block with `prep()`, `exec()`, `post()` lifecycle (see `pocketflow/docs/core_abstraction/node.md`)
- **Flow**: Orchestrator connecting nodes using action strings for transitions (see `pocketflow/docs/core_abstraction/flow.md`)
- **Shared Store**: In-memory dictionary for inter-node communication (see `pocketflow/docs/core_abstraction/communication.md`)
- **Batch**: Components for data-intensive tasks (BatchNode, BatchFlow)
- **Async & Parallel**: Advanced components (excluded from MVP)

Always read the documentation in `pocketflow/docs` and relevant examples in `pocketflow/cookbook` when needed for any task that requires using the pocketflow framework.

*All documentation follows a single-source-of-truth principle. Each concept has one canonical document, with other documents linking to it rather than duplicating content.*

> Remember: Proactively use subagents when reading documentation, examples and codeexcept for small lookups. If you need specific information, ask a subagent to do the research for you, tailor the prompt to the task at hand and provide as much context as possible.

### Current State of the Project

The codebase is in early development with these tasks completed:
- âœ… PocketFlow framework added to the codebase including `pocketflow/docs` and `pocketflow/cookbook`
- âœ… Comprehensive documentation infrastructure in `docs/`
- âœ… Development tooling and testing setup
- âœ… Task 1: Package setup and CLI entry point with `pflow` command and version subcommand
- âœ… Task 2: Basic CLI run command with stdio/stdin support
- âœ… Task 3: Execute a Hardcoded 'Hello World' Workflow
- âœ… Task 4: Implement IR-to-PocketFlow Object Converter
- âœ… Task 5: Node discovery and registry implementation
- âœ… Task 6: Define JSON IR schema
- âœ… Task 7: Extract node metadata from docstrings
- âœ… Task 8: Build comprehensive shell pipe integration with stdin/stdout
- âœ… Task 11: Implement read-file and write-file nodes
- âœ… Task 16: Create planning context builder
- âœ… Task 14: Implement type, structure, description and semantic documentation for all Interface components
- âœ… Task 15: Extend context builder for two-phase discovery and structure documentation support (modify and extend the context builder implemented in Task 16)
- âœ… Task 18: Template Variable System
- âœ… Task 19: Implement Node Interface Registry (Node IR) for Accurate Template Validation - moved interface parsing to scan-time, eliminating false validation failures
- âœ… Task 20: Implement Nested Workflow Execution
- âœ… Task 21: Implement Workflow Input Declaration - workflows to declare their expected input and output parameters in the IR schema
- âœ… Task 24: Implement Workflow Manager (A centralized service that owns the workflow lifecycle - save/load/resolve)
- âœ… Task 12: Implement LLM Node - Create a general-purpose LLM node - infinitely reusable building block by combining prompts with template variables
- âœ… Task 26: Implement GitHub and Git Operation Nodes - 9 nodes for GitHub/Git automation
- âœ… Task 17: Implement Natural Language Planner System (complete planner meta-workflow that transforms natural language into workflows)
- âœ… Task 30: Refactor Validation Functions from compiler.py
- âœ… Task 31: Refactor Test Infrastructure - Mock at LLM Level
- âœ… Task 27: Implement intuitive debugging capabilities and tracing system for the planner
- âœ… Task 9: Implement shared store collision detection using automatic namespacing
- âœ… Task 33: Extract planner prompts to markdown files in `src/pflow/planning/prompts/` and improve/create test cases for each prompt in `tests/test_planning/llm/prompts/`
- âœ… Task 34: Prompt Accuracy Tracking System for planner prompts
- âœ… Task 35: Migrate Template Syntax from $variable to ${variable}
- âœ… Task 36: Update Context Builder for Namespacing Clarity
- âœ… Task 37: Implement API Error Handling with User-Friendly Messages
- âœ… Task 40: Improve Workflow Validation and Consolidate into Unified System
- âœ… Task 41: Implement Shell Node
- âœ… Task 28: Improve performance of planner by modifying prompts (Discovery, Component Browsing, Metadata Generation, Parameter Prompts, Workflow Generator)

Next up:
- ğŸ¤– Task 43: MCP Server support (install mcps and use as virtual nodes) <- This is what we are building now!
- â³ Task 32: Unified Metrics and Tracing System for User Workflow Execution
- â³ Task 10: Create registry CLI
- â³ Task 42: Claude Code Agentic Node
- â³ Task 22: Named workflow execution

Next version (post-MVP/post-Launch):
- â³ Task 46: Workflow Export to Zero-Dependency Code
- â³ Task 38: Support conditional Branching in Generated Workflows
- â³ Task 39: Support Parallel Execution in Workflows
- â³ Task 44: Build caching system
- â³ Task 45: Evaluate if wrapping n8n is worth the effort

*Update this list as you complete tasks.*

> We are currently building the MVP and have NO USERS using the system. This means that we NEVER have to worry about backwards compatibility or breaking changes. However, we should never break existing functionality or rewrite breaking tests without carefully considering the implications.

## User Decisions and Recommendations

Every time you need the user to make a decision, you should:
1. Create a new markdown file in the folder `scratchpads/<conversation-subject>/critical-user-decisions/` and write down the details about the decision and the reasoning why it is needed.
2. Give at least 2 options with clear recommendations.
3. Add a markdown checkbox for each option so the user can select the option they prefer easily.

> Important: Do not proceed to implementation until the user has made a decision and you have a clear understanding of the decision and its implications.

**Remember** You are an AI agent and you *are not able to make decisions for the user*. You are only able to provide information and recommendations. The user is the one who makes the final decision if anything is unclear or ambigous in the documentation.

### Example formatting for presenting the user with a decision

```markdown
## 1. Decision Title - Decision importance (1-5)

Describe the decision and the reasoning why it is needed.

### Context:

Describe the context around the problem so it can be understood clearly in isolation.

### Options:

- [x] **Option A: ...
  - Reasoning for why this is a good and bad option
  - ...
  - ...

- [ ] **Option B: ...
  - ...
  - ...

**Recommendation**: Option A - Reasoning for why this might be the best option.
```

> If the decision importance is 1-2 and you are confident in the decision, you can make the decision for the user and does not need to ask the user for confirmation or document the decision in the scratchpad.

### Decision Escalation Framework

Escalate to user when:
- Architectural decisions affect multiple components
- Trade-offs have no clear winner after analysis
- Current approach contradicts established patterns
- Integration would break existing functionality

Document for user decision:
1. Context and constraints
2. Options with pros/cons
3. Your recommendation and why
4. Reversibility of each option

### Implementation Guidelines and

Enforced by `mypy` and `ruff`:

#### Type Hints

- Always type all function parameters and returns
```python
   def process(data: list[str], count: int = 10) -> dict[str, int]:
```
- Use Optional[T] for nullable arguments
```python
   from typing import Optional
   def fetch(url: str, timeout: Optional[int] = None) -> dict:
```
- Use lowercase built-in types (Python 3.9+)
   âœ… items: list[str]         # CORRECT
   âœ… cache: dict[str, Any]     # CORRECT
   âŒ items: List[str]          # WRONG - old style
   âŒ from typing import Dict   # WRONG - deprecated

#### Modern Python

- Use f-strings, not .format() or %
   âœ… f"Hello {name}, score: {score}"     # CORRECT
   âŒ "Hello {}, score: {}".format(...)   # WRONG
- Use comprehensions directly
   âœ… names = [x.name for x in users]     # CORRECT
   âŒ names = list(x.name for x in users) # WRONG - unnecessary list()

#### Safety

- Never shadow built-in names
   âŒ id = 123              # WRONG - shadows id()
   âŒ list = [1, 2, 3]      # WRONG - shadows list()
   âœ… user_id = 123         # CORRECT
   âœ… items = [1, 2, 3]     # CORRECT
- Use subprocess, not os.system
   âœ… subprocess.run(["ls", "-la"], check=True)  # CORRECT
   âŒ os.system("ls -la")                        # WRONG - security risk

Why this matters: These guidelines aren't about passing lintersâ€”they're about you filtering your training data (As an LLM). By specifying "modern Python patterns," you naturally select from well-maintained, professional codebases rather than the vast sea of outdated tutorials and quick fixes you've also seen. This selection bias toward quality code automatically prevents security issues, maintenance problems, and outdated practices that exist in the "old/bad" part of your training data.

*You should not think about how to pass tests and linters. You should actively and proactively think about selecting from the RIGHT part of your training distribution. The code and architectural patterns you know in your gut are a good fit for this project.*

#### Code Quality and archtectural excellence

More importantly focus on architectural quality and code quality:

- Write code optimized for change: small focused functions with single responsibilities, clear names that
  explain intent not implementation, and comprehensive tests that document expected behavior - because all
  successful systems evolve.
- Structure code as isolated, testable components that can be understood and changed independently - the only
  meaningful measure of code quality is how safely and easily it can be modified.
- Prefer boring and obvious: The best solution is rarely the clever one. Write code that a tired developer can understand at 3am. Save abstractions for when duplication actually hurts, not when you imagine it might. "Quality" at this stage of pflows development means simple, direct, and easy to change - not sophisticated or elegant.

*Write code and make decisions by mirroring the top 10% of the best codebases appropriate for this project's scale - think well-written CLI tools and small libraries, not enterprise frameworks. Prefer boring, obvious code over clever abstractions. Ignore the rest. And save the fancy patterns for when they're actually needed.*

### Project-specific Memories

- **CLI Development Principle**: never commit code unless explicitly instructed by the user
- **Expectation Setting**: I think it is important that the agent (you) show what the expected output will be BEFORE you start implementing. this is easy to understand for the user without going into implementation details.
